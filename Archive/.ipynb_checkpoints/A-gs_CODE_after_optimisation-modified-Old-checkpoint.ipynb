{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2978442-0a0a-42b2-ac0f-8e6b685580d8",
   "metadata": {},
   "source": [
    "# A-gs model and implementation (simulation CO2 and H2O flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5053646-e207-4e8c-a62e-2a7f70ad0887",
   "metadata": {},
   "source": [
    "## Initialize data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467470b3-2427-4ada-b14f-9ff26922d8ec",
   "metadata": {},
   "source": [
    "### Setup and fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515abf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "Username   = 'Beheerder'\n",
    "years      = range(2017,2021)    #(1997,2021) # Set years to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath   = os.path.join('../')\n",
    "print('datapath is set to %s'%datapath)\n",
    "\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install plotly \n",
    "# !pip install cufflinks\n",
    "#!pip install colorspacious\n",
    "#!pip install seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "#import cufflinks as cf\n",
    "import matplotlib.dates as mdate\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm\n",
    "#from colorspacious import cspace_converter\n",
    "import scipy.stats as stats\n",
    "#cf.go_offline()\n",
    "# cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(datapath,'PythonScripts'))\n",
    "from Loobos_Toolbox import dateparse, dateparse_Gapfilled, Read_LoobosEddFinal, Read_LooStor, Read_LoodatGapfill, Read_Loobos_halfhourly, Read_Loobos_meteo, Read_Loobos_soil, Read_Loobos_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these next two lines are to prevent re-loading the data. If you want to re-load data, instead comment them out\n",
    "if not 'progress' in globals(): progress = list()\n",
    "if not 'dataloaded' in progress:\n",
    "  # Read files\n",
    "    df_EC           = Read_LoobosEddFinal    (years,datapath)\n",
    "    df_Stor         = Read_LooStor           (years,datapath)\n",
    "    df_Comb         = Read_LoodatGapfill     (years,datapath)\n",
    "    df_NEE          = Read_Loobos_halfhourly (years,datapath)\n",
    "    df_meteo        = Read_Loobos_meteo      (years,datapath)\n",
    "    df_soil         = Read_Loobos_soil       (years,datapath) \n",
    "    df_profile      = Read_Loobos_profile    (years,datapath)\n",
    "    progress.append('dataloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make filter for GPP orginial data and not gabfilled\n",
    "I = ((df_Comb['GPP_fqc']==0)&(df_meteo['PAR']>0))\n",
    "\n",
    "# Filter for CO2 data\n",
    "t = df_profile.index                                          \n",
    "time = (t < np.datetime64('2013-05-08')) | (t > np.datetime64('2013-06-01'))\n",
    "CO2 = (df_profile['CO2level1'] > 300)\n",
    "\n",
    "#General filter\n",
    "I = ((df_Comb['GPP_fqc']==0)&(df_meteo['PAR']>0))\n",
    "\n",
    "df_meteo_CO2 = df_meteo[time][CO2]\n",
    "df_meteo_filter = df_meteo_CO2[I]\n",
    "# print(df_meteo_CO2_filter['PAR'])\n",
    "\n",
    "df_Comb_CO2 = df_Comb[time][CO2]\n",
    "df_Comb_filter = df_Comb_CO2[I]\n",
    "# print(df_Comb_CO2_filter['GPP_f'])\n",
    "\n",
    "df_profile_CO2 = df_profile[time][CO2]\n",
    "df_profile_filter = df_profile_CO2[I]\n",
    "# print(df_profile_CO2_filter['CO2level1'])\n",
    "\n",
    "df_EC_CO2 = df_EC[time][CO2]\n",
    "df_EC_filter = df_EC_CO2[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca8ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPP_f_mg = df_Comb_filter['GPP_f']/1000000 * 44.01 * 1000 # from umolm-2s-1 to molm-2s-1, to gm-2s-1, to mgm-2s-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1996767-09d3-441d-b711-cea73a750854",
   "metadata": {},
   "source": [
    "### Define A-gs model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE after optimisation\n",
    "\n",
    "#Calculate canopy resistance and CO2 assimilation/respiration\n",
    "def runAgs():\n",
    "    \n",
    "            #fluxes using the A-Gs scheme.\n",
    "        co2_ppm   = df_profile_filter['CO2level1']\n",
    "        epsi      = 1.   # epsilon\n",
    "        sigma     = 5.67E-8\n",
    "        Tair_K    = df_Comb_filter['Tair'] + 273.  # This is the air temperature\n",
    "        Ts_K      = ((df_meteo_filter['L(o)corr'] / (epsi * sigma))**0.25) # This is the surface temperature, which should be used in the model\n",
    "        Ts_C      = Ts_K - 273.\n",
    "        conv_fac  = 101.3 / (8.314 * Tair_K)       # converstion factor, obtained via the ideal gas law. mol / m3\n",
    "        co2_mgm3  = (co2_ppm * 44.01) * conv_fac   # concentration * conversion factor * molar mass CO2.  mgm3 = ppm * g/mol / mol/m3\n",
    "        Ts        = Ts_C\n",
    "\n",
    "        rho_1     = 1.225            # Density of air kg/m3\n",
    "\n",
    "            # Fixed constants \n",
    "        Q10gm     = 2.0              # Parameter to calculate the mesophyll conductance\n",
    "        Q10am     = 2.0              # Parameter to calculate max primary productivity\n",
    "        Q10gamma  = 2                # Parameter to calculate the CO2 compensation concentration. (2 in IFS, 1.5 in DALES)\n",
    "\n",
    "            # Reference temperatures calculation mesophyll conductance:\n",
    "        T1gm      = 273 - 273        # Converted to degreesC\n",
    "        T2gm      = 309 - 273        # IFS=309, DALES=301 (default)\n",
    "\n",
    "            # Reference temperatues calculation max primary productivity:\n",
    "        T1Am      = 273 - 273        # IFS=281, DALES=286 (C4))   Converted to degrees C\n",
    "        T2Am      = 313 - 273        # IFS=309, DALES=301 \n",
    "\n",
    "        nuco2q    = 1.6              # Ratio molecular viscosity water to carbon dioxide\n",
    "        gmin      = 0.25 / 1000.     # Cuticular (minimum) conductance. NOTE: = g_cu in IFS, with a factor 1000 difference (m/s)\n",
    "        ad        = 0.07             # Regression coefficient to calculate Cfrac (kpa-1)\n",
    "        Kx        = 0.7              # Extinction coefficient PAR (mground / mleaf)\n",
    "\n",
    "            # Maximum quantum use efficiency\n",
    "        epsilon0  =  0.0144    # Maximum quantum use efficiency. mgCO2 / J PAR. Also named alpha\n",
    "\n",
    "            # Vegetation specific constants\n",
    "        gm298_umol    = 0.09                        # obtained from litature: Knauer et al. 2018: Effects of mesophyll conductance .....\n",
    "        gm298         = gm298_umol / conv_fac       # converted to (mm/s)\n",
    "        Ammax298      = 2.6                         # CO2 maximal primary productivity\n",
    "        f0            = 0.89                        # Maximum value Cfrac \n",
    "        co2_comp298   = (42 * 44.01) * (1/24.45)    # from ppm to mg/m3. Got value 42 from the Atmospheric boundary layer book\n",
    "\n",
    "        #LAI trees (m2 m-2)\n",
    "        LAI           = 2.1                         # Obtained from data measurements in Loobos 2021.\n",
    "\n",
    "            # Constant molar mass  \n",
    "        constants_M_co2 = 44.01\n",
    "        constants_M_air = 28.97\n",
    "\n",
    "\n",
    "            # Calculate the CO2 compensation concentration (IFS eq. 8.92)\n",
    "            # \"The compensation   point Γ is defined as the CO2 concentration at which the net CO2 assimilation of a fully lit leaf becomes zero.\"\n",
    "\n",
    "        co2_comp = co2_comp298 * Q10gamma ** ((Ts - 25) / 10) # equation 8.92. co2_comp = mg/m3.\n",
    "\n",
    "            # Calculate the mesophyll conductance (IFS eq. 8.93)\n",
    "            # \"The mesophyll conductance gm describes the transport of CO2 from the substomatal cavities to the mesophyll cells where the carbon is fixed.\"\n",
    "\n",
    "        gm       = (gm298 * Q10gm **((Ts -25)/10)) / ((1. + np.exp(0.3*(T1gm - Ts)))*(1. + np.exp(0.3*(Ts - T2gm)))) \n",
    "        gm       = gm / 1000. # convert to m/s\n",
    "\n",
    "            # Calculate CO2 concentration inside the leaf (Ci)\n",
    "        fmin0    = gmin/nuco2q - (1./9.) * gm\n",
    "\n",
    "            # Calculate the minimum value of Cfrac\n",
    "        fmin     = gmin /(gmin +gm) # Formula from IFS\n",
    "        # fmin    = -fmin0 + ((fmin0 **2) + 4* gmin/nuco2q *gm)**0.5 / (2. *gm) # formula from DALES\n",
    "\n",
    "\n",
    "        VPD      = df_Comb_filter['VPD']/10     #Our measurement data from Loobos converted to kPa (/10). Ds in Dales\n",
    "\n",
    "        VPDmax   = (f0 - fmin) /ad   # VPDmax in kPa. Dmax in Dalese\n",
    "\n",
    "            # Calculate the fraction of the concentration inside the leaf in comparison with the surface of the leaf. \n",
    "        cfrac    = f0 * (1 - VPD/VPDmax) + fmin * (VPD/VPDmax) # f in IFS.\n",
    "\n",
    "            # Absolute CO2 concentration (mg/m3)\n",
    "        co2_abs  = co2_mgm3 \n",
    "\n",
    "            # CO2 concentration in leaf (mg/m3)\n",
    "        ci       = cfrac * (co2_abs - co2_comp) + co2_comp\n",
    "\n",
    "            # Max gross primary production in high light conditions \n",
    "            #  line 439 / formula 8.94. Ammax is in mg/m2/s\n",
    "        Ammax    = (Ammax298 * Q10am ** ((Ts - 25)/10)) / ((1. + np.exp(0.3*(T1Am - Ts)))*(1. + np.exp(0.3*(Ts - T2Am))))\n",
    "\n",
    "            # Gross assimilation rate (Am, IFS eq. 8.97). In mg/m2/s\n",
    "        Am       = Ammax * (1 - np.exp(-(gm *(ci - co2_comp) / Ammax))) \n",
    "\n",
    "            # Autotrophic dark respiration (IFS eq. 8.99). In mg/m2/s\n",
    "        Rdark    = Am / 9\n",
    " \n",
    "            # Photosynthetically active radiation (PAR), Ia\n",
    "        PAR      = df_meteo_filter['PAR'] * 0.22 # measured Loobos data. Convert from umol m-2 s-1 to Jm-2s-1\n",
    "\n",
    "            # Calculate e (maximum quantum use efficiency) Also named as alpha. mgCO2 / J PAR\n",
    "        epsilon  = epsilon0 * (co2_abs - co2_comp)/(co2_abs + 2. * co2_comp) # Formula from DALES\n",
    "\n",
    "            # calculate the gross primary productivity (mg/m2/s)            \n",
    "        Ag       = (Am + Rdark) * (1 - np.exp((-epsilon * PAR)/(Am + Rdark))) - Rdark # Formula 8.98\n",
    "\n",
    "         \n",
    "            # Calculate upscaling from leaf to canopy: net flow CO2 into the plant (An) [-]   \n",
    "        tempy    = epsilon * Kx * PAR / (Am + Rdark)\n",
    "\n",
    "        def E1(x):\n",
    "            # E1() approximation\n",
    "                euler = 0.5772156649015329\n",
    "                G     = np.exp(-euler)\n",
    "                b     = (2*(1-G)/(G*(2-G)))**0.5\n",
    "                h_inf = (1-G)*(G**2 - 6*G+12) / (3*G*(2-G)**2*b)\n",
    "                q     = 20/47*x**(31/26.)**0.5\n",
    "                h     = 1 / (1+x*x**0.5)\n",
    "                E1    = np.exp(-x) / (G+(1-G)*np.exp(-x/(1-G))) * np.log(1+G/x-(1-G)/(h+b*x)**2)\n",
    "                return E1\n",
    "\n",
    "            # Calculate the net assimilation\n",
    "\n",
    "                # 1.- calculate upscaling from leaf to canopy: net flow CO2 into the plant  \n",
    "        E1_first    = E1(tempy * np.exp(-Kx*LAI))\n",
    "        E1_second   = E1(tempy)\n",
    "        An_canopy   = (Am + Rdark) * (1 - 1. / (Kx * LAI) * (E1_first - E1_second)) # code from DALES\n",
    "\n",
    "                # 2.- calculate upscaling from leaf to canopy: CO2 conductance at canopy level\n",
    "        a1          = 1.0 / (1 - f0)\n",
    "        Dstar       = VPDmax / (a1 * (f0 - fmin))\n",
    "\n",
    "        fstr        = 1.     # ranges from 0: values at wilting point, to 1: absence of moisture stress\n",
    "        gcco2       = LAI * (gmin / nuco2q + a1 * fstr * An_canopy / ((co2_abs - co2_comp) * (1. + VPD / Dstar))) # m/s\n",
    "\n",
    "                # 3. calculate surface resistance for moisture and carbon dioxide\n",
    "        rs          = 1. / (1.6 * gcco2)\n",
    "        rsCO2       = 1. / gcco2         # Surface resistance of CO2 in s/m\n",
    "\n",
    "\n",
    "                # calculate the ra, aerodynamic resistance\n",
    "        U           = df_EC_filter['Mea_Windsp']\n",
    "        U_star      = df_EC_filter['U-star']\n",
    "        ra          = U / (U_star**2)             # get the ra from the Loobos observations\n",
    "\n",
    "\n",
    "        # 4.  calculate net flux of CO2 into the plant (An, mg/m2/s)\n",
    "        An_final    = (co2_abs - ci) / (ra + rsCO2)   # should have as default a minus sign before the formula\n",
    "        # The assimilation rate (A) is expressed as amount of CO2 assimilated per unit leaf area and time (mol m−2 s−1)\n",
    "        # end of Jamie's code\n",
    "\n",
    "        #I want to convert to umol carbon /m2/s . Molar weight of CO2 is 44.01g/mol\n",
    "        An_umol = (An_final / 44.01 )*1000\n",
    "\n",
    "        return(An_final, An_umol, rs, ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_final,an_umol,rs, ra = runAgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71027a44-ef3b-4f05-802d-862198eb87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.loc['2017-04-01':'2017-05-01'].plot(label='rs',legend='rs')\n",
    "ra.loc['2017-04-01':'2017-05-01'].plot(label='ra',legend='ra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0753ef-8f5b-4b55-83db-ad31419a0e53",
   "metadata": {},
   "source": [
    "## Calcuate ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d717-ea63-477c-9c43-8a29262f3143",
   "metadata": {},
   "source": [
    "### Assemble dataframe 'df_ET' that will hold output and fill with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065217e-ea3f-4cfc-97af-76ad200b8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET = pd.concat([df_meteo['L(o)'],df_meteo['Te-L(o)'],df_profile['Pressure'],df_Comb['VPD'],df_Comb['rH'],df_meteo['P(mast)']],axis=1,sort=False)\n",
    "#convert Pressure from hPa to kPa \n",
    "df_ET['p_kPa']=df_ET['Pressure']/10\n",
    "df_ET['VPD_adj']=df_ET['VPD'].loc[df_ET['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "df_ET['VPD_adj']=df_ET['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f94f14-69d7-4d8a-a720-5531d86ec058",
   "metadata": {},
   "source": [
    "### step 1) leaf temperature 'T_sfc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2083b5-cc4a-4c1d-8da6-c6d16c338ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting outgoing Longwave: the sensor measures values between -20 and 10, but that it because the blackbody emission from the sensor itself (dependent on the temp of the sensor) is not taken into account.\n",
    "#thus we must take the output of the sensor and add the emitted longwave radiation of the sensor itself.\n",
    "#R_L(out)_corrected = R_L(out)_measured + R_L(out)_sensor, where R_L(out)_sensor = sigma*T(sensor)^4\n",
    "\n",
    "#constants:\n",
    "sigma = 5.67e-8 # W/m2/K4, Stefan-boltzmann constant\n",
    "epsilon = 1/0.98\n",
    "df_ET['L(o)_sensor'] = sigma*((df_ET['Te-L(o)']+273)**4)    #where Te-L(o) is in C\n",
    "df_ET['L(o)_corr'] = df_ET['L(o)'] + df_ET['L(o)_sensor'] # where L(o)_corr is corrected Longwave out (corrected for sensor's own temp)\n",
    "#df_ET['L(o)_corr'].plot() # varies from 300 to 500 Wm-2\n",
    "\n",
    "#Formula for leaf temp is: R_L(out)_corrected = epsilon * sigma * T_sfc^4 (where epsilon = 0.98-1.00, sigma = 5.67e-8 W/m2/K4, T_sfc in K)\n",
    "#rearrange formula to:\n",
    "df_ET['T_sfc'] = (df_ET['L(o)_corr'] / (epsilon*sigma)) ** (1/4)  # T_sfc output in K)\n",
    "df_ET['T_sfc_C'] = df_ET['T_sfc']-273\n",
    "#check output:\n",
    "df_ET['T_sfc_C'].plot(title=\"Leaf surface temp 'T_sfc_C' in Celcius\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd48e79-4f83-4918-88fd-31dc73f4063f",
   "metadata": {},
   "source": [
    "### step 2) saturated vapor pressure 'e_sat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e002423-dc98-467a-8548-74cad7fa518d",
   "metadata": {},
   "source": [
    "#### calculating e_sat assuming T_sfc is in Kelvin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f589699-a1cf-4e45-80bb-c9023990611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating e_sat from T_sfc_C, note that T_sfc_C ranges from -150 C to -250 C (suspicious)\n",
    "#constants:\n",
    "e_sat_0 = 0.6107 # e_sat_0 = 0.6107 kPa or 610.7 Pa\n",
    "a = 7.5\n",
    "b = 237.3 # oC (geen typo)\n",
    "df_ET['e_sat'] = e_sat_0 * 10**(a*df_ET['T_sfc_C'] / (b+df_ET['T_sfc_C'])) #  T_sfc_C in oC\n",
    "\n",
    "#formal clausius-Clapeyron (aka August-Roche-Magnus) from wikipedia: e_sat = e_sat_0 * 10^( 17.6*Temp / 243+ Temp)  where e_sat is in hPa and Temp is in K\n",
    "\n",
    "p1=df_ET['e_sat'].plot(title=\"saturated vapor pressure 'e_sat' in kPa\")\n",
    "#p1.axhline(y=100,c='r')\n",
    "#p1.axhline(y=0.40,c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde10abf-a388-477d-8a42-ab3d08dedf40",
   "metadata": {},
   "source": [
    "#### wikipedia formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae3173-9802-42c0-86c9-502207493cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING WIKIPEDIA FORMULA INSTEAD OF ONE GIVEN BY MICHIEL\n",
    "#calculating e_sat from T_sfc, note that T_sfc ranges from 0 K to (suspicious)\n",
    "#constants:\n",
    "#e_sat_0 = 0.6107 # e_sat_0 = 0.6107 kPa or 610.7 Pa\n",
    "#a = 17.6\n",
    "#b = 243 # oC (geen typo)\n",
    "#df_ET['e_sat_wiki'] = e_sat_0 * 10**(a*df_ET['T_sfc'] / (b+df_ET['T_sfc'])) #  T_sfc in K\n",
    "\n",
    "#formal clausius-Clapeyron (aka August-Roche-Magnus) from wikipedia: e_sat = e_sat_0 * 10^( 17.6*Temp / 243+ Temp)  where e_sat is in hPa and Temp is in K\n",
    "\n",
    "#p1=df_ET['e_sat_wiki'].plot(title=\"saturated vapor pressure 'e_sat' in hPa (using Wikipedia formula) \")\n",
    "#p1.axhline(y=100,c='r')\n",
    "#p1.axhline(y=0.40,c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd594a-9f80-4f40-8c1a-dfe307e39a96",
   "metadata": {},
   "source": [
    "### step 3) ET from VPD and Esat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf62e3-a391-44fc-b576-114f005082f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VPD(in Pa) = e_sat - e_act\n",
    "#VPD(in kg/kg) = q_sat - q_act\n",
    "\n",
    "Rd = 287 # J/kg K\n",
    "Rv = 462 # J/kg K\n",
    "# e = vapour pressure # in Pa of kPa\n",
    "# p = air pressure # in Pa of kPa\n",
    "\n",
    "#Je kunt specific humidity q in kg/kg berekenen uit vapour pressure e via:\n",
    "#q = Rd/Rv * e/p\n",
    "\n",
    "#q_sat = Rd/Rv * e_sat/p\n",
    "df_ET['q_sat'] = Rd/Rv * df_ET['e_sat']/df_ET['p_kPa']\n",
    "\n",
    "#method 1 of calculating e_act: through VPD from dataset\n",
    "#note: this is giving negative values so I'm removing it for now.\n",
    "#VPD = e_sat - e_act -> e_act = e_sat - VPD\n",
    "df_ET['e_act_fromVPD'] = df_ET['e_sat'] - df_ET['VPD_adj']\n",
    "\n",
    "#q_act = Rd/Rv * e_act/p\n",
    "df_ET['q_act_fromVPD'] = Rd/Rv * df_ET['e_act_fromVPD']/df_ET['p_kPa'] #adding this to check\n",
    "\n",
    "#final step, subtract to get VPD for specific humidity\n",
    "#VPD_q = q_sat-q_act\n",
    "df_ET['VPDq_fromVPD']=df_ET['q_sat'] - df_ET['q_act_fromVPD'] #adding this to check if there's a substantial difference\n",
    "\n",
    "#method 2 of calculating e_act: through Rel Humidity from dataset\n",
    "# RH = e_act/e_sat *100 -> e_act = RH * e_sat /100\n",
    "df_ET['e_act_fromRH'] = (df_ET['rH']/100)*df_ET['e_sat']\n",
    "\n",
    "#q_act = Rd/Rv * e_act/p\n",
    "df_ET['q_act_fromRH'] = Rd/Rv * df_ET['e_act_fromRH']/df_ET['p_kPa']\n",
    "\n",
    "#final step, subtract to get VPD for specific humidity\n",
    "#VPD_q = q_sat-q_act\n",
    "df_ET['VPDq_fromRH']=df_ET['q_sat'] - df_ET['q_act_fromRH']\n",
    "\n",
    "#df_ET['VPDq_fromVPD'].plot(title='VPD (calculated from VPD) in kg(vapor)/kg(air)')\n",
    "df_ET['VPDq_fromRH'].plot(title='VPD (caldulated from RH) in kg(vapor)/kg(air)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefabae-3fc8-403c-b5b1-512bebb858e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the differences between the methods\n",
    "#df_ET['e_act_diff']=df_ET['e_act_fromVPD']-df_ET['e_act_fromRH']\n",
    "#df_ET['e_act_diff'].plot()\n",
    "#df_ET['e_sat'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f907e1-0e0b-4fc6-9b2f-1831559e4197",
   "metadata": {},
   "source": [
    "### step 4) ET in Wm-2 from VPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13421fc-ce43-451f-a688-ea72d941b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final step\n",
    "#ET = rho * Lv * VPD/rs\n",
    "#rho = 1.2 (approx value given by Michiel), Lv = 2260 kJ/kg (from google) Note: update to more accurate values when I can\n",
    "\n",
    "df_ET['ET'] = 1.2 * 2260000 * (df_ET['VPDq_fromRH']/rs)\n",
    "df_ET['ET_VPD'] = 1.2 * 2260000 * (df_ET['VPDq_fromVPD']/rs)\n",
    "df_ET['ET_VPD2'] = 1.2 * 2260000 * (df_ET['VPDq_fromVPD']/(rs+ra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6f816-f099-4e7d-a971-f4d269101d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.plot()\n",
    "#rs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae9be1-8d01-49b8-9084-ec4dc5aa3254",
   "metadata": {},
   "source": [
    "## End of Calculating ET section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f89cf-1c76-41d9-8d80-531591d2d441",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3b611-32d2-4ac9-8147-4c0cf4329857",
   "metadata": {},
   "source": [
    "### yearly overviews of CO2 and H2O fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d23972-4dec-4feb-bda3-861319a71907",
   "metadata": {},
   "source": [
    "#### Water (ET and LE) yearly overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e1ebf-1425-4dd9-af46-771974b6b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulated ET\n",
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "ET_plotting_2017 = df_ET['ET_VPD2'].loc['2017-04-01':'2017-09-30'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(ET_plotting_2017)\n",
    "ax.set_ylabel('ET [W/m2]')\n",
    "plt.suptitle('simulated ET in Wm-2 for 2017 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "#2018\n",
    "fig, ax = plt.subplots()\n",
    "ET_plotting_2018 = df_ET['ET_VPD2'].loc['2018-04-01':'2018-09-30'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(ET_plotting_2018)\n",
    "ax.set_ylabel('ET [W/m2]')\n",
    "plt.suptitle('simulated ET in Wm-2 for 2018 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c70db0-1714-43a5-957d-fae4afb24e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measured LE\n",
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "LE_plotting_2017 = df_Comb['LE'].loc[df_Comb['LE']>0].loc['2017-04-01':'2017-09-30'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(LE_plotting_2017)\n",
    "ax.set_ylabel('ET [W/m2]')\n",
    "plt.suptitle('measured LE in Wm-2 for 2017 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "#2018\n",
    "fig, ax = plt.subplots()\n",
    "LE_plotting_2018 = df_Comb['LE'].loc[df_Comb['LE']>0].loc['2018-04-01':'2018-09-30'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(LE_plotting_2018)\n",
    "ax.set_ylabel('ET [W/m2]')\n",
    "plt.suptitle('measured LE in Wm-2 for 2018 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "#difference 2017\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(ET_plotting_2017)\n",
    "ax.plot(LE_plotting_2017,c='r')\n",
    "fig.legend(['simulated','measured'])\n",
    "plt.show()\n",
    "#difference 2017\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(ET_plotting_2018)\n",
    "ax.plot(LE_plotting_2018,c='r')\n",
    "fig.legend(['simulated','measured'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c2d7e-9f46-40f6-95f7-4486106b3d82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Carbon (An and GPP) yearly overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f23930-1a7f-4537-8abb-2b443eeef9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulated An\n",
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "an_plotting_2017 = an_umol.loc[an_umol>0].loc['2017-04-01 00:00':'2017-10-01 00:00'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(an_plotting_2017)\n",
    "ax.set_ylabel('Assimilation [umol/m2/s]')\n",
    "plt.suptitle('A-gs simulated Assimilation rate for 2017 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "#2018\n",
    "fig, ax = plt.subplots()\n",
    "an_plotting_2018 = an_umol.loc[an_umol>0].loc['2018-04-01 00:00':'2018-10-01 00:00'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(an_plotting_2018)\n",
    "ax.set_ylabel('Assimilation [umol/m2/s]')\n",
    "plt.suptitle('A-gs simulated Assimilation rate for 2018 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52182cd-e99d-40f9-9182-d936006b9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measured GPP\n",
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "GPP_plotting_2017 = df_Comb['GPP_f'].loc['2017-04-05 00:00':'2017-10-01 00:00'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(GPP_plotting_2017)\n",
    "ax.set_ylabel('GPP [umol/m2/s]')\n",
    "plt.suptitle('Measured GPP for 2017 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()\n",
    "#2018\n",
    "fig, ax = plt.subplots()\n",
    "GPP_plotting_2018 = df_Comb['GPP_f'].loc['2018-04-05 00:00':'2018-10-01 00:00'].between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(GPP_plotting_2018)\n",
    "ax.set_ylabel('GPP [umol/m2/s]')\n",
    "plt.suptitle('Measured GPP for 2018 growth season, between 11:00 and 18:00')\n",
    "plt.grid()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d73df-65eb-4a2c-9140-7249b9a9b9ca",
   "metadata": {},
   "source": [
    "### Day-scale comparison measured and simulated GPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4932c-fde5-4f10-b7a4-f2293d268eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the CO2 flux, presumably in mol/area/time, we take it from .....\n",
    "#this can be split up in a respiration and assimilation flux. For assimilation we take it using night time representative values over time\n",
    "#An_final is in mg/m2/s, therefor use an_umol\n",
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "an_plotting_apr2017 = an_umol.loc[an_umol>0].loc['2017-04-14 00:00':'2017-04-16 00:00']#.between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(an_plotting_apr2017)\n",
    "ax.set_ylabel('Assimilation [umol/m2/s]')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('A-gs simulated assimilation (GPP) for 14-16 april 2017')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "gpp_plotting_apr2017=df_Comb['GPP_f'].loc['2017-04-14 00:00':'2017-04-16 00:00']\n",
    "ax.plot(gpp_plotting_apr2017)\n",
    "ax.set_ylabel('GPP [umol/m2/s]')\n",
    "#fig.autofmt_xdate()\n",
    "fig.suptitle('EC-measured GPP_f for 14-16 april 2017')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gpp_plotting_apr2017-an_plotting_apr2017)\n",
    "ax.set_ylabel('GPP [umol/m2/s]')\n",
    "#fig.autofmt_xdate()\n",
    "fig.suptitle('EC-measured GPP_f minus A-gs simulated An for 14-16 april 2017')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf377e4-dac7-4df4-9ea2-26aeb911215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "fig, ax = plt.subplots()\n",
    "an_plotting_apr2017 = df_ET['ET'].loc['2018-08-01 00:00':'2018-08-03 00:00']\n",
    "ax.plot(an_plotting_apr2017)\n",
    "ax.set_ylabel('LE [W/m2]')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('Simulated ET for 1-2 august 2018')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "gpp_plotting_apr2017=df_Comb['LE'].loc[df_Comb['LE']>0].loc['2018-08-01':'2018-08-02']#.between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(gpp_plotting_apr2017)\n",
    "ax.set_ylabel('measured LE [W/m2]')\n",
    "#fig.autofmt_xdate()\n",
    "fig.suptitle('EC-measured LE for 1-2 august 2018')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gpp_plotting_apr2017-an_plotting_apr2017)\n",
    "ax.set_ylabel('LE [umol/m2/s]')\n",
    "#fig.autofmt_xdate()\n",
    "fig.suptitle('EC-measured LE minus A-gs simulated ET for 1-2 august 2018')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84353ce3-5656-49e3-8778-02b86ae33943",
   "metadata": {},
   "source": [
    "## Troubleshooting ET LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0c2a7-be4d-4d43-a896-d1dc7bd3c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017\n",
    "start,end = '2017-05-01','2017-05-30'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "simRH_plotting = df_ET['ET'].loc[start:end]\n",
    "measured_plotting = df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end]#.between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(an_plotting)\n",
    "ax.set_ylabel('LE [W/m2]')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('from RH')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "simVPD_plotting = df_ET['ET_VPD'].loc[start:end]\n",
    "measured_plotting=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end]#.between_time(\"11:00\", \"18:00\")\n",
    "ax.plot(measured_plotting)\n",
    "ax.plot(simVPD_plotting,c='red') #for troubleshoot\n",
    "ax.set_ylabel('LE [W/m2]')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('from VPD')\n",
    "plt.grid()\n",
    "fig.legend(['measured','simulated'])\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gpp_plotting-an_plotting)\n",
    "ax.set_ylabel('LE [umol/m2/s]')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('EC-measured LE minus A-gs simulated ET')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeaab71-6290-4464-bc2d-685fa0897ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET['L(o)'].loc[start:end].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868d56d-8dbe-44fd-a44d-a92bcfdc2c98",
   "metadata": {},
   "source": [
    "## Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc463c-0db0-4905-8e14-acc8f405d020",
   "metadata": {},
   "source": [
    "### H2O flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166d0f7-a34a-4470-bdc2-ec09a1fd3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data=df_ET['ET'].loc['2017-05-01 00:00':'2017-05-30 00:00'].resample('3H').mean().between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc['2017-05-01 00:00':'2017-05-30 00:00'].resample('3H').mean().between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "df_tmp = pd.DataFrame()\n",
    "df_tmp['sim_data']=sim_data\n",
    "\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742603c-8b07-448e-b955-0810cfa36961",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bbb75-c7c4-429e-b032-80e1162b72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(df_tmp['LE'],df_tmp['sim_data']) #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r')\n",
    "ax.set_xlabel('measured data LE (EC) [Wm-2]')\n",
    "ax.set_ylabel('simulated data ET (A-gs) [Wm-2]')\n",
    "fig.suptitle('correlation of simulated ET to measured LE. from 1st to 30th May 2017, (3hour mean, all hours) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8859bf-ea71-409e-85b1-ab61bcd87d6e",
   "metadata": {},
   "source": [
    "### CO2 flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aad3ea-7f34-42d0-a5a6-c5fd7544243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"legend.loc\"]=\"center right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2211734-c58e-4cf5-a18d-e726977c33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data=an_umol.loc[an_umol>0].loc['2017-05-01 00:00':'2017-05-30 00:00'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['GPP_f'].loc['2017-05-01 00:00':'2017-05-30 00:00'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "df_tmp = pd.DataFrame()\n",
    "df_tmp['sim_data']=sim_data\n",
    "\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07511a8d-2eba-443f-a5e3-5ade59b3a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['GPP_f'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe2489-4834-4f8e-bcfa-9221f5875855",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['GPP_f'],df_tmp['sim_data'],c=df_tmp.index.hour,cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-5,40)\n",
    "ax.set_xlim(-5,40)\n",
    "ax.set_xlabel(r'measured data An (GPP_f) [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax.set_ylabel(r'simulated data An (A-gs) [$\\mu molm^{-2}s^{-1}$]')\n",
    "fig.suptitle('Correlation of simulated to measured An, May 2017, (3hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0ac3e-dbf0-4d94-ba47-e1897fe7fee5",
   "metadata": {},
   "source": [
    "#### quick check R2 for different months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ede45-5b1f-425a-bce1-63ba76a5fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "        \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "        \n",
    "        sim_data=an_umol.loc[an_umol>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['GPP_f'].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        df_tmp = pd.DataFrame()\n",
    "        df_tmp['sim_data']=sim_data\n",
    "        \n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['GPP_f'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),' R2: {:.3f}'.format(r_value**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594dc6d-f20c-4dab-b092-5ebf3bca3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "        \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "\n",
    "        sim_data=df_ET['ET'].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        df_tmp = pd.DataFrame()\n",
    "        df_tmp['sim_data']=sim_data\n",
    "        \n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),' R2: {:.3f}'.format(r_value**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "        \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "\n",
    "        sim_data=df_ET['ET_VPD'].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        df_tmp = pd.DataFrame()\n",
    "        df_tmp['sim_data']=sim_data\n",
    "        \n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),' R2: {:.3f}'.format(r_value**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4975a4-4f67-4791-bec3-69061fd4ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_dailysum(df):\n",
    "    df['daily_prec']=np.nan\n",
    "    df_tmp = df.resample('1D').sum()\n",
    "    for idx,row in df.iterrows():\n",
    "        df.loc[idx,'daily_prec']=df_tmp.loc['{}-{}-{}'.format(idx.year,idx.month,idx.day) ,'P(mast)'] #iloc[row, column]\n",
    "        #row['daily_prec']=\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3cf7d-0652-4c76-a5f9-eea1fc6ad530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_lasthours(df):\n",
    "    df['daily_prec']=np.nan\n",
    "    df_tmp = df.resample('1D').sum()\n",
    "    for idx,row in df.iterrows():\n",
    "        df.loc[idx,'daily_prec']=df_tmp.loc['{}-{}-{}'.format(idx.year,idx.month,idx.day) ,'P(mast)'] #iloc[row, column]\n",
    "        #row['daily_prec']=\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342c4ce-2a5e-46ec-a443-55f9b4ee1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "#USING THE NEW FUNCTION p_dailysum\n",
    "\n",
    "df_ET_1=p_dailysum(df_ET)\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "        \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "\n",
    "        sim_data = df_ET_1.loc[start:end,('ET_VPD2','daily_prec')]\n",
    "        sim_data = sim_data.loc[sim_data['daily_prec']==0.0]\n",
    "        sim_data= sim_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        #df_tmp = pd.DataFrame()\n",
    "        df_tmp=sim_data.copy()\n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        #print(df_tmp)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD2'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),'Slope:{:.3f} R2: {:.3f}'.format(slope,r_value**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378a14f-b755-4efa-b833-d7f41b42edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET_1['Hour']=df_ET_1.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf1845-c2b6-4da2-99e1-4e0604933eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-draw better correlation plot\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-05-01 00:00'\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD2','daily_prec')]\n",
    "sim_data = sim_data.loc[sim_data['daily_prec']==0.0]\n",
    "sim_data= sim_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD2'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD2'],c=df_tmp.index.hour,cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation of simulated to measured LE. May 2017, (3hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.set_title('(Only days on which daily  sum of Precip. is 0)')\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b60f6-6c46-4729-9e3e-0b8702898f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work in progress, alternative function for eliminating data with precipitation but based on previous 3 hours instead of daily sum\n",
    "#def p_resample(df,hours=3):\n",
    "#    df[output]=NaNs\n",
    "#    i=0\n",
    "#    j=hours\n",
    "#    for range(rows-hours) in df:\n",
    "#        df[output][j]=df[i:j].sum()\n",
    "#        i++1\n",
    "#        j++1\n",
    "#        \n",
    "#    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce76d4-c59f-4b66-a64b-539dffd9b8b3",
   "metadata": {},
   "source": [
    "### hourly averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e2fab-a26c-4d91-b633-96abb24722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2017-04-01 00:00'\n",
    "end='2017-05-01 00:00'\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD2','daily_prec')]\n",
    "sim_data = sim_data.loc[sim_data['daily_prec']==0.0]\n",
    "sim_data= sim_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "sim_data['ET_VPD2'].plot()\n",
    "measured_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4f29e-0733-4fcf-b5e0-90155c195f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-draw better correlation plot\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-05-01 00:00'\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD2','daily_prec')]\n",
    "sim_data = sim_data.loc[sim_data['daily_prec']==0.0]\n",
    "sim_data= sim_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD2'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD2'],c=df_tmp.index.hour,cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation of simulated to measured LE. May 2017, (3hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.set_title('(Only days on which daily  sum of Precip. is 0)')\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bae4c5-05f3-40c2-808d-acc6b2b293e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93575c1b-b49d-4149-8300-974ca8af37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil['SM-Lit'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-003'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-020'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-050'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-100'].loc['2017-01-01':'2017-12-30'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a7a0d-f711-4177-8aee-2e9d5c5867f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 471.85,
   "position": {
    "height": "493.844px",
    "left": "1539.19px",
    "right": "20px",
    "top": "105px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
