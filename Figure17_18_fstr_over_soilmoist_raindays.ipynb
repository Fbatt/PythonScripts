{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2978442-0a0a-42b2-ac0f-8e6b685580d8",
   "metadata": {},
   "source": [
    "# A-gs model and implementation (simulation CO2 and H2O flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5053646-e207-4e8c-a62e-2a7f70ad0887",
   "metadata": {},
   "source": [
    "## Initialize data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467470b3-2427-4ada-b14f-9ff26922d8ec",
   "metadata": {},
   "source": [
    "### Setup and fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515abf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "Username   = 'Beheerder'\n",
    "years      = range(2001,2021)    #(1997,2021) # Set years to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = os.path.join('../')\n",
    "#print('datapath is set to %s'%datapath)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "#import cufflinks as cf\n",
    "import matplotlib.dates as mdate\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm\n",
    "#from colorspacious import cspace_converter\n",
    "import scipy.stats as stats\n",
    "#cf.go_offline()\n",
    "#cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(datapath,'PythonScripts'))\n",
    "from Loobos_Toolbox import dateparse, dateparse_Gapfilled, Read_LoobosEddFinal, Read_LooStor, Read_LoodatGapfill, Read_Loobos_halfhourly, Read_Loobos_meteo, Read_Loobos_soil, Read_Loobos_profile\n",
    "from Ags_model import runAgs, calc_LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd4fbe-bb75-4187-85d1-6728a7da3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these next two lines are to prevent re-loading the data. If you want to re-load data, instead comment them out\n",
    "if not 'progress' in globals(): progress = list()\n",
    "if not 'dataloaded' in progress:\n",
    "  # Read files\n",
    "    df_EC           = Read_LoobosEddFinal    (years,datapath)\n",
    "    df_Stor         = Read_LooStor           (years,datapath)\n",
    "    df_Comb         = Read_LoodatGapfill     (years,datapath)\n",
    "    df_NEE          = Read_Loobos_halfhourly (years,datapath)\n",
    "    df_meteo        = Read_Loobos_meteo      (years,datapath)\n",
    "    df_soil         = Read_Loobos_soil       (years,datapath) \n",
    "    df_profile      = Read_Loobos_profile    (years,datapath)\n",
    "    progress.append('dataloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5b45d-abab-4516-b5e8-7e8867acd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FilterData import Filter_wrap\n",
    "CO2,Locorr,VPD,Ustar,df_profile_filter,df_meteo_filter,df_Comb_filter,df_EC_filter=Filter_wrap(df_Comb,df_profile,df_meteo,df_EC,filterversion='default')\n",
    "#NOTE: df_Stor is NOT FILTERED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c575c9-374b-4c4a-952f-b1696e6437d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FilterData import Filter_GPP_LE_NEE_VPD \n",
    "df_Comb_filter2 = Filter_GPP_LE_NEE_VPD(df_Comb,fqc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae8ffc-59a1-4474-a75a-a73a24f87318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for manually checking data\n",
    "#st='2008-01-01'\n",
    "#ed='2019-12-30'\n",
    "#df_meteo.loc[st:ed,'L(o)'].plot()\n",
    "#df_meteo.loc[st:ed,'L(o)corr'].plot()\n",
    "#df_meteo.loc[st:ed,'Te-L(o)'].plot()\n",
    "#df_profile.loc[st:ed,'CO2level1'].plot()\n",
    "#df_profile.loc[st:ed,'Pressure'].plot()\n",
    "#df_Comb.loc[st:ed,'VPD'].plot()\n",
    "#df_Comb.loc[st:ed,'Tair'].plot()\n",
    "#df_Comb.loc[st:ed,'GPP_fqc'].plot()\n",
    "#df_EC.loc[st:ed,'U-star'].plot()\n",
    "#df_EC.loc[st:ed,'Mea_Windsp'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1996767-09d3-441d-b711-cea73a750854",
   "metadata": {},
   "source": [
    "### Import knmi rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5590bc-8a73-43f1-b170-8a5f04608453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath = os.path.join('../KNMI_regen')\n",
    "#print(datapath)\n",
    "knmi_regen=pd.read_csv('../KNMI_regen/neerslaggeg_KOOTWIJK-RADIO_567.txt',sep=',',header=17)\n",
    "knmi_regen=knmi_regen.iloc[28000:] #remove dataset before ~november 2007\n",
    "#knmi_regen=knmi_regen.iloc[31000:] #remove dataset before ~november 2007\n",
    "knmi_regen['date']=pd.to_datetime(knmi_regen['YYYYMMDD'],yearfirst=True,format='%Y%m%d')\n",
    "knmi_regen.index=knmi_regen['date']\n",
    "knmi_regen=knmi_regen.rename(columns={\"   RD\": \"RD\", \"   SX\": \"SX\"}) #for some reason there's spaces in some of the column names, removing them.\n",
    "knmi_regen=knmi_regen.astype({\"RD\": np.intc})\n",
    "knmi_regen['RD'].plot() #Column RD is is rain daily sum, SX is code related to snow. If unnamed contains 4 spaces it's also a code for snow. STN is station ID.\n",
    "df_rain=knmi_regen.loc[:,['RD']].resample('3H').ffill()\n",
    "#df_rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bec3f3-5f19-4c00-b66f-cbf61a06233c",
   "metadata": {},
   "source": [
    "### Run A-gs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run A-gs model\n",
    "#TODO: DEFINITIVELY REPLACE OLD FILTER WITH NP.WHERE FILTER, I TEMP HOTFIXED IT HERE:\n",
    "an_final,an_umol,rs, ra = runAgs(df_profile_filter,df_Comb_filter2,df_meteo_filter,df_EC_filter,fstr=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0753ef-8f5b-4b55-83db-ad31419a0e53",
   "metadata": {},
   "source": [
    "## Calcuate ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d717-ea63-477c-9c43-8a29262f3143",
   "metadata": {},
   "source": [
    "### Assemble dataframe 'df_ET' that will hold output and fill with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065217e-ea3f-4cfc-97af-76ad200b8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: UPDATE THIS FUNCTION EVERYWHERE TO ACTUALLY USE FILTERED VALUES!!!!\n",
    "def init_ETframe(rs_series):\n",
    "    df_ET = pd.concat([df_meteo_filter['L(o)'],df_meteo_filter['Te-L(o)'],df_profile_filter['Pressure'],df_Comb_filter['VPD'],df_Comb_filter['rH'],df_meteo_filter['P(mast)']],axis=1,sort=False)\n",
    "    #convert Pressure from hPa to kPa \n",
    "    df_ET['p_kPa']=df_ET['Pressure']/10\n",
    "    df_ET['VPD_adj']=df_ET['VPD'].loc[df_ET['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "    df_ET['VPD_adj']=df_ET['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa\n",
    "    df_ET['rs']=rs_series.to_frame(name=\"rs\")\n",
    "    df_ET['ra']=ra.to_frame(name=\"ra\")\n",
    "    return df_ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1ead7-7694-4619-8496-bd27e4ece452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET=init_ETframe(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77211664-888c-4840-ba39-a1dde1890967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET=calc_LE(df_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf194f7b-9be7-494e-9ed2-6bfd232baf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in precipitation last 3h and 24 hour values so it can be used for filtering\n",
    "df_ET['last3day_prec']=df_ET['P(mast)'].rolling('72H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f94f14-69d7-4d8a-a720-5531d86ec058",
   "metadata": {},
   "source": [
    "## end of calculate ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc463c-0db0-4905-8e14-acc8f405d020",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Manually checking datasets for extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78b239-6b6c-4e39-832b-7ad1cd936b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Comb_filter['LE'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a41e5e-71ea-4407-ae05-b83b01ee1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Comb_filter2['LE'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb7b8a-ba39-4a3f-9c85-895bac837881",
   "metadata": {},
   "source": [
    "# fstr analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2233c0-6976-4dfd-bc5e-41fdd9cb240f",
   "metadata": {},
   "source": [
    "### step 1 assemble dataframe and chop up according to each week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99e5fa-4315-4c62-a720-ade8c2964def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp30m=pd.DataFrame()\n",
    "df_tmp30m['ET']=df_ET['ET_VPD']\n",
    "df_tmp30m['P(mast)']=df_ET['P(mast)']\n",
    "df_tmp30m=df_tmp30m.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3720e5-1fcf-4b97-b67c-d61e4b66a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp30m=pd.DataFrame()\n",
    "df_tmp30m['ET']=df_ET['ET_VPD']\n",
    "df_tmp30m['P(mast)']=df_ET['P(mast)']\n",
    "df_tmp30m=df_tmp30m.dropna()\n",
    "\n",
    "df_LE=df_Comb['LE'].loc[df_Comb['LE']>=0]\n",
    "df_tmp30m=df_tmp30m.merge(df_LE, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "#df_tmp30['ET/LE']=df_tmp30['ET']/df_tmp30['LE']\n",
    "#df_tmp30m['LE/ET']=df_tmp30m['LE']/df_tmp30m['ET'] #<- this is the one we want, observations/model. If obs/model = fstr, then model*fstr= model(obs/model) = obs\n",
    "\n",
    "df_tmp30m['P_3day']=df_tmp30m['P(mast)'].rolling('72H').sum()\n",
    "#df_tmp30m=df_tmp30m.loc[df_tmp30m['P_3day']==0]\n",
    "\n",
    "df_tmp3h=df_tmp30m.resample('3H').mean()#.between_time(\"09:00\", \"15:00\")\n",
    "df_tmp3h['P(mast)']=df_tmp30m['P(mast)'].resample('3H').sum() #overwrite the averaged pmast with sum pmast\n",
    "df_tmp3h['P_3day']=df_tmp3h['P(mast)'].rolling('72H').sum() #overwrite the correct P_3day\n",
    "\n",
    "#remove rainy days through knmi data\n",
    "df_tmp3h['RD']=df_rain['RD']\n",
    "df_tmp3h['RD']=df_tmp3h['RD']/10 #convert from tenths of mm to mm\n",
    "df_tmp3h=df_tmp3h.loc[df_tmp3h['RD']==0]\n",
    "\n",
    "#remove rainy days through Pmast\n",
    "df_rain3h_dailymax=df_tmp3h['P(mast)'].resample('1D').sum().resample('3H').ffill()\n",
    "df_rain3h_dailymax=df_rain3h_dailymax[:-1] #remove last entry because all 3h frames end on 21:00 not 00:00\n",
    "df_rain3h_dailymax=df_rain3h_dailymax.rename('P(mast)Dmax')\n",
    "df_tmp3h['P(mast)Dmax']=df_rain3h_dailymax\n",
    "df_tmp3h=df_tmp3h.loc[df_tmp3h['P(mast)Dmax']==0]\n",
    "\n",
    "#manual filter remove bad days\n",
    "listofdates =  ['2008-08-24',\n",
    "                '2010-05-11',\n",
    "                '2010-08-04',\n",
    "                '2012-06-13',\n",
    "                '2013-05-10',\n",
    "                '2013-05-19',\n",
    "                '2014-06-16',\n",
    "                '2017-04-22']\n",
    "\n",
    "#for date in listofdates:\n",
    "#    df_tmp3h.loc[date+' 00:00':date+' 21:00','ET'] = np.nan\n",
    "#    df_tmp3h.loc[date+' 00:00':date+' 21:00','LE'] = np.nan\n",
    "\n",
    "#remove hours outside of 9:00 and 15:00\n",
    "#df_tmp3h=df_tmp3h.between_time(\"09:00\", \"15:00\")\n",
    "\n",
    "#resample to daily\n",
    "df_tmp1d=df_tmp3h.resample('1D').mean()\n",
    "df_tmp1d['doy']=df_tmp1d.index.dayofyear\n",
    "df_tmp1d['P(mast)sum']=df_tmp3h['P(mast)'].resample('1D').sum()\n",
    "df_tmp1d['LE/ET']=df_tmp1d['LE']/df_tmp1d['ET']\n",
    "\n",
    "#resample to weekly (7 days)\n",
    "df_tmp7d=df_tmp3h.resample('7D').mean()\n",
    "df_tmp7d['LE/ET']=df_tmp7d['LE']/df_tmp7d['ET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64f18a-8ea4-432c-9e9c-dfb6bf2b2fef",
   "metadata": {},
   "source": [
    "### visualize each year to see whats going wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c0ed3-4ef4-4129-835e-34b035a95ea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## plotting fstr over time for growthseason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a29b7-5e39-49a9-9f7c-8d55df9420de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### plotting fstr over time for growthseason some years colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211de573-11b8-4c8f-a324-1508d402161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "#remove non-growthseason values\n",
    "df_tmp7d=df_tmp7d.loc[(df_tmp7d.index.month>=4) & (df_tmp7d.index.month<=9)]\n",
    "\n",
    "df_tmp7d['weeknr']=df_tmp7d.index.isocalendar().week\n",
    "\n",
    "#df_tmp7d=df_tmp7d.loc[df_tmp7d['LE/ET']<=1.0]\n",
    "\n",
    "#df_tmp\n",
    "\n",
    "#df_tmp['ET/LE'].plot(ylim=(0,15))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_ylim(0,2)\n",
    "ax.set_ylabel('fstr (=LEobs/LEsim)')\n",
    "ax.set_xlabel('weeknr')\n",
    "\n",
    "plt.xticks([x for x in range(14,41)]) #this sets the xticks for the main x-axis with the weeknr\n",
    "locs, labels=plt.xticks() #this same function with no argument gets the position and labels and stores them for later\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.15))\n",
    "\n",
    "# Turn on the frame for the twin axis, but then hide all \n",
    "# but the bottom spine\n",
    "ax2.set_frame_on(True)\n",
    "ax2.patch.set_visible(False)\n",
    "\n",
    "ax2.set_xlabel('approx month')\n",
    "ax2.set_xlim(13,41)\n",
    "ax2.set_xticks([14, 18, 22, 26,  30, 34, 39])\n",
    "ax2.set_xticklabels(['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct'])\n",
    "\n",
    "colored_years={'2003':'green','2006':'orange','2007':'magenta','2011':'#b62020','2018':'blue','2019':'cyan'}\n",
    "\n",
    "for year in ['2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2017','2018','2019']:\n",
    "    start=year+'-01-01 01:00'\n",
    "    end=year+'-12-23 23:00'\n",
    "    if year in colored_years.keys():\n",
    "        color=colored_years[year]\n",
    "        marker='^'\n",
    "    else:\n",
    "        color='grey'\n",
    "        marker=''\n",
    "    #marker={'2008':'^','2009':'^','2010':'^','2011':'^','2012':'o','2013':'^','2014':'o','2015':'^','2016':'o','2017':'o','2018':'^'}\n",
    "    #colors={'2008':'#b62020','2009':'#cb2424','2010':'^','2011':'^','2012':'o','2013':'^','2014':'o','2015':'^','2016':'o','2017':'o','2018':'^'}\n",
    "    #df_tmp.loc[start:end,'ET/LE'].plot(x=df_tmp.loc[start:end,'weeknr'],ylim=(0,15))\n",
    "    ax.plot(df_tmp7d.loc[start:end,'weeknr'],df_tmp7d.loc[start:end,'LE/ET'], marker=marker,color=color ,label=year) #marker=marker[year]\n",
    "ax.legend(loc=(\"upper left\"))\n",
    "ax.set_title('fstr (=LEobs/LEsim) on week-basis for 2001-2020 growth seasons (Apr-Sept), 3-hour means for 09:00-15:00, rainy days removed')\n",
    "#ax.set_title('fstr=0: witing point , fstr=1: no water stress')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d0c9e-ae19-4bb1-b8b7-705fbfb88761",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### fstr over time all years colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ebcc6-1a90-4e2e-a2ef-55fd9b0b4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "#remove non-growthseason values\n",
    "df_tmp7d=df_tmp7d.loc[(df_tmp7d.index.month>=4) & (df_tmp7d.index.month<=9)]\n",
    "\n",
    "df_tmp7d['weeknr']=df_tmp7d.index.isocalendar().week\n",
    "\n",
    "#df_tmp7d=df_tmp7d.loc[df_tmp7d['LE/ET']<=1.0]\n",
    "\n",
    "#df_tmp\n",
    "\n",
    "#df_tmp['ET/LE'].plot(ylim=(0,15))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_ylim(0,1.5)\n",
    "ax.set_ylabel('fstr (=LEobs/LEsim)')\n",
    "ax.set_xlabel('weeknr')\n",
    "\n",
    "plt.xticks([x for x in range(14,41)]) #this sets the xticks for the main x-axis with the weeknr\n",
    "locs, labels=plt.xticks() #this same function with no argument gets the position and labels and stores them for later\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.15))\n",
    "\n",
    "# Turn on the frame for the twin axis, but then hide all \n",
    "# but the bottom spine\n",
    "ax2.set_frame_on(True)\n",
    "ax2.patch.set_visible(False)\n",
    "\n",
    "ax2.set_xlabel('approx month')\n",
    "ax2.set_xlim(13,41)\n",
    "ax2.set_xticks([14, 18, 22, 26,  30, 34, 39])\n",
    "ax2.set_xticklabels(['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct'])\n",
    "\n",
    "\n",
    "for year in ['2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2017','2018','2019']:\n",
    "    start=year+'-01-01 01:00'\n",
    "    end=year+'-12-23 23:00'\n",
    "    if int(year)>=2010:\n",
    "        marker='s'\n",
    "    else:\n",
    "        marker='o'\n",
    "\n",
    "    ax.plot(df_tmp7d.loc[start:end,'weeknr'],df_tmp7d.loc[start:end,'LE/ET'], marker=marker ,label=year) #marker=marker[year]\n",
    "ax.legend(loc=(\"upper left\"))\n",
    "fig.suptitle('fstr (=LEobs/LEsim) on week-basis for april t/m sept, 09:00-15:00, rainy days removed')\n",
    "ax.set_title('fstr=0: witing point , fstr=1: no water stress')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42881ce9-3fbd-4609-88ef-30900a2a4d3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### plotting fstr over time some other years colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd77ed-32ef-4bf0-a51c-0510777e1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "#remove non-growthseason values\n",
    "df_tmp7d=df_tmp7d.loc[(df_tmp7d.index.month>=4) & (df_tmp7d.index.month<=9)]\n",
    "\n",
    "df_tmp7d['weeknr']=df_tmp7d.index.isocalendar().week\n",
    "\n",
    "#df_tmp7d=df_tmp7d.loc[df_tmp7d['LE/ET']<=1.0]\n",
    "\n",
    "#df_tmp\n",
    "\n",
    "#df_tmp['ET/LE'].plot(ylim=(0,15))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_ylim(0,1.5)\n",
    "ax.set_ylabel('fstr (=LEobs/LEsim)')\n",
    "ax.set_xlabel('weeknr')\n",
    "\n",
    "plt.xticks([x for x in range(14,41)]) #this sets the xticks for the main x-axis with the weeknr\n",
    "locs, labels=plt.xticks() #this same function with no argument gets the position and labels and stores them for later\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.15))\n",
    "\n",
    "# Turn on the frame for the twin axis, but then hide all \n",
    "# but the bottom spine\n",
    "ax2.set_frame_on(True)\n",
    "ax2.patch.set_visible(False)\n",
    "\n",
    "ax2.set_xlabel('approx month')\n",
    "ax2.set_xlim(13,41)\n",
    "ax2.set_xticks([14, 18, 22, 26,  30, 34, 39])\n",
    "ax2.set_xticklabels(['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct'])\n",
    "\n",
    "colored_years={'2003':'green','2006':'orange','2011':'#b62020','2013':'purple','2018':'blue'}\n",
    "\n",
    "for year in ['2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2017','2018','2019']:\n",
    "    start=year+'-01-01 01:00'\n",
    "    end=year+'-12-23 23:00'\n",
    "    if year in colored_years.keys():\n",
    "        color=colored_years[year]\n",
    "        marker='^'\n",
    "    else:\n",
    "        color='grey'\n",
    "        marker=''\n",
    "    #marker={'2008':'^','2009':'^','2010':'^','2011':'^','2012':'o','2013':'^','2014':'o','2015':'^','2016':'o','2017':'o','2018':'^'}\n",
    "    #colors={'2008':'#b62020','2009':'#cb2424','2010':'^','2011':'^','2012':'o','2013':'^','2014':'o','2015':'^','2016':'o','2017':'o','2018':'^'}\n",
    "    #df_tmp.loc[start:end,'ET/LE'].plot(x=df_tmp.loc[start:end,'weeknr'],ylim=(0,15))\n",
    "    ax.plot(df_tmp7d.loc[start:end,'weeknr'],df_tmp7d.loc[start:end,'LE/ET'], marker=marker,color=color ,label=year) #marker=marker[year]\n",
    "ax.legend(loc=(\"upper left\"))\n",
    "fig.suptitle('fstr (=LEobs/LEsim) on week-basis for april t/m sept, 09:00-15:00, rainy days removed')\n",
    "ax.set_title('fstr=0: witing point , fstr=1: no water stress')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3e45e-260f-4678-bbc8-2600ccbaf05a",
   "metadata": {},
   "source": [
    "## end of plotting fstr over time for growthseason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f7c02-828f-416a-9d88-88e355680d3f",
   "metadata": {},
   "source": [
    "## soil moisture anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f20b76-5734-4d20-b932-bd7a8fd3bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate anomalies monthly precipitation time series from a monthly precipitation time series, \n",
    "#subtract the mean value of each month across all years from the original value of that month in each year\n",
    "\n",
    "#(value soil moisture in that year)-mean soil moisture across all years\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbb0f5-c434-4320-8766-0e247c375012",
   "metadata": {},
   "source": [
    "## soil moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aea404-37b0-4371-a550-b91ee1ec616e",
   "metadata": {},
   "source": [
    "## Groundwater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b691ec8-2256-404b-875b-e007dbbac570",
   "metadata": {},
   "source": [
    "### import groundwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e890931-e569-4fa0-893b-4e1f367b40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ground water as sequeltial time series\n",
    "df_GWS_daily_1 = pd.read_csv('GWS_daily.csv')\n",
    "df_GWS_daily_1['datetime']=pd.to_datetime(df_GWS_daily_1['datetime'])\n",
    "df_GWS_daily_1.index=df_GWS_daily_1['datetime']\n",
    "df_GWS_daily_1.drop(columns=['datetime'],inplace=True) \n",
    "df_GWS_daily_1\n",
    "#columns are datetime (index) depth, depth_anom_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e515c54-0753-4c6f-8ca1-6f72a48ad828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ground water as sequeltial time series\n",
    "#import ground water sorted by day of year, each year in column\n",
    "df_GWS_multi = pd.read_csv('GWS_multi_daily.csv')\n",
    "df_GWS_multi['yeardate']=pd.to_datetime(df_GWS_multi['yeardate'])\n",
    "df_GWS_multi.index=df_GWS_multi['yeardate']\n",
    "df_GWS_multi.drop(columns=['Unnamed: 0'],inplace=True) \n",
    "df_GWS_multi\n",
    "#columns: yeardate (index) monthday (note! a str in form of mm-dd)\tdepth_2001\tdepth_2001_diff\tdepth_2001_anom\tdepth_2002\tdepth_2002_diff\tdepth_2002_anom\tdepth_2003\tdepth_2003_diff\tdepth_2003_anom\t...\tdepth_2016_anom\tdepth_2017\tdepth_2017_diff\tdepth_2017_anom\tdepth_2018\tdepth_2018_diff\tdepth_2018_anom\tdepth_2019\tdepth_2019_diff\tdepth_2019_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9bf6a9-e3c1-4a4e-814b-f63f4a88d4ac",
   "metadata": {},
   "source": [
    "### end of import groundwater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dde0c0-44dc-4ffa-9f50-bd542dacbf9d",
   "metadata": {},
   "source": [
    "## Plot GWS over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7fe3c-2aba-4ede-b160-d723485ffe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_GWS_multi # all years\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "#ax.set_ylim(0,1.5)\n",
    "ax.set_ylabel('GW delta since april 1st')\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "#plt.xticks([x for x in range(14,41)]) #this sets the xticks for the main x-axis with the weeknr\n",
    "#locs, labels=plt.xticks() #this same function with no argument gets the position and labels and stores them for later\n",
    "\n",
    "#fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "\n",
    "\n",
    "colored_years={'2003':'green','2006':'orange','2011':'#b62020','2013':'purple','2018':'blue'}\n",
    "\n",
    "for year in ['2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2017','2018','2019']:\n",
    "    start=year+'-04-01'\n",
    "    end=year+'-10-30'\n",
    "    if year in colored_years.keys():\n",
    "        color=colored_years[year]\n",
    "        marker=''\n",
    "    else:\n",
    "        color='grey'\n",
    "        marker=''\n",
    "    ax.plot(df_GWS_multi['yeardate'],df_GWS_multi['depth_'+year+'_diff'], marker=marker ,label=year) \n",
    "ax.legend(loc=(\"upper left\"))\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=[1,15]))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
    "\n",
    "fig.suptitle('Ground water depth relative to depth at start of growth season that year')\n",
    "ax.set_title('GW_delta = GW_depth(current of that year) - GW_depth(april 1st of that year)')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adb192-d8b4-408c-98c2-897692c6e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df_GWS_multi #years that stay down\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "#ax.set_ylim(0,1.5)\n",
    "ax.set_ylabel('GW delta since april 1st')\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "#plt.xticks([x for x in range(14,41)]) #this sets the xticks for the main x-axis with the weeknr\n",
    "#locs, labels=plt.xticks() #this same function with no argument gets the position and labels and stores them for later\n",
    "\n",
    "#fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "#colored_years={'2003':'green','2008':'orange', 2009'2011':'#b62020','2013':'purple','2018':'blue'}\n",
    "#2003 2008 2009 2010 (2011) 2013 2014  2018 2019\n",
    "\n",
    "grey_years=['2001','2002','2004','2005','2006','2007','2010','2011','2012','2015','2016','2017']\n",
    "\n",
    "#\n",
    "for year in ['2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']:\n",
    "    start=year+'-04-01'\n",
    "    end=year+'-10-30'\n",
    "    if year in grey_years:#colored_years.keys():\n",
    "        marker=''\n",
    "        ax.plot(df_GWS_multi['yeardate'],df_GWS_multi['depth_'+year+'_diff'], marker=marker, color='grey' ,label='')\n",
    "    else:\n",
    "        marker=''\n",
    "        ax.plot(df_GWS_multi['yeardate'],df_GWS_multi['depth_'+year+'_diff'], marker=marker, zorder=3 ,label=year)\n",
    "ax.legend(loc=(\"upper left\"))\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=[1,15]))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
    "\n",
    "fig.suptitle('Ground water depth relative to depth at start of growth season that year')\n",
    "ax.set_title('GW_delta = GW_depth(current of that year) - GW_depth(april 1st of that year)')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efc0b8-497d-44c1-baad-747ed6a5454b",
   "metadata": {},
   "source": [
    "## End of Plot GWS over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a547f62-2cc6-4296-9eac-44601f977a0c",
   "metadata": {},
   "source": [
    "## Plotting fstr sensitivity analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492d2d5-8700-413f-8244-b63ef8849454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "\n",
    "#parallel processing\n",
    "\n",
    "#df_GWS_multi7d=df_GWS_multi.iloc[:,2:].resample('7D').mean()\n",
    "\n",
    "df_1d=pd.DataFrame()\n",
    "\n",
    "df_1d=df_tmp3h.resample('1D').mean()\n",
    "\n",
    "#df_1d=df_tmp30m.resample('1D').mean()\n",
    "#df_1d['P(mast)']=df_tmp30m['P(mast)'].resample('1D').sum() #precip needs to be sum, not mean.\n",
    "\n",
    "df_1d=df_1d.loc[df_1d['P(mast)']==0.0]\n",
    "df_1d=df_1d.loc[df_1d['RD']==0.0] #knmi rain data\n",
    "\n",
    "df_1d['LE/ET']=df_1d['LE']/df_1d['ET']\n",
    "df_1d=df_1d.loc[df_1d['LE/ET']<1.2]\n",
    "\n",
    "#df_1d=df_1d.merge(df_GWS_multi['GWS_2003_diff'], how='inner',left_index=True, right_index=True)\n",
    "#df_1d=df_1d.merge(dfGWS['anom'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for year in range(2001,2020):\n",
    "    \n",
    "    \n",
    "    st=str(year)+\"-04-01\"\n",
    "    ed=str(year)+\"-09-30\"\n",
    "    st2=\"2000-04-01\" #due to df_GWS_multi being indexed to the year 2000, we need extra set of st and ed\n",
    "    ed2=\"2000-09-30\"\n",
    "    GWS_key='depth_'+str(year)+'_diff' #the column name to ask for\n",
    "    df_tmp=pd.DataFrame()\n",
    "    df_tmp[GWS_key]=df_GWS_multi.loc[st2:ed2,[GWS_key]]\n",
    "    df_tmp['rel_date'] = df_tmp.index.strftime(date_format=str(year)+'-%m-%d')\n",
    "    df_tmp['rel_date'] = pd.to_datetime(df_tmp['rel_date'],format='%Y-%m-%d')\n",
    "    df_tmp.index=df_tmp['rel_date']\n",
    "    #print(df_tmp.index)\n",
    "\n",
    "    df_tmp=df_tmp.merge(df_1d.loc[st:ed,['LE/ET']], how='inner',left_index=True, right_index=True)\n",
    "    ax.scatter(df_tmp[GWS_key],df_tmp['LE/ET'],color='b',s=5)\n",
    "    ax.set_xlabel('GW delta')\n",
    "    ax.set_ylabel('fstr')\n",
    "    #ax.set_xlim(-5,90)\n",
    "    #ax.set_ylim(0,1.2)\n",
    "    ax.set_title('fstr over groundwater level change since april, \\n ')\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "#df_GWS_multi7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c9f05-7ab0-4f28-a2c8-49ba740e724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "#sequential processing of GWS diff\n",
    "#df_GWS_multi7d=df_GWS_multi.iloc[:,2:].resample('7D').mean()\n",
    "\n",
    "df_1d=pd.DataFrame()\n",
    "\n",
    "df_1d=df_tmp3h.resample('1D').mean()\n",
    "\n",
    "#df_1d=df_tmp30m.resample('1D').mean()\n",
    "#df_1d['P(mast)']=df_tmp30m['P(mast)'].resample('1D').sum() #precip needs to be sum, not mean.\n",
    "\n",
    "df_1d=df_1d.loc[df_1d['P(mast)']==0.0]\n",
    "df_1d=df_1d.loc[df_1d['RD']==0.0] #knmi rain data\n",
    "\n",
    "df_1d['LE/ET']=df_1d['LE']/df_1d['ET']\n",
    "df_1d=df_1d.loc[df_1d['LE/ET']<1.0]\n",
    "\n",
    "\n",
    "df_1d_seq=pd.DataFrame() #sequential dataframe\n",
    "\n",
    "for year in range(2001,2020):\n",
    "    \n",
    "    st=str(year)+\"-04-01\"\n",
    "    ed=str(year)+\"-09-30\"\n",
    "    st2=\"2000-04-01\" #due to df_GWS_multi being indexed to the year 2000, we need extra set of st and ed\n",
    "    ed2=\"2000-09-30\"\n",
    "    GWS_key='depth_'+str(year)+'_diff' #the column name to ask for\n",
    "    df_tmp=pd.DataFrame()\n",
    "    df_tmp[GWS_key]=df_GWS_multi.loc[st2:ed2,[GWS_key]]\n",
    "    df_tmp['rel_date'] = df_tmp.index.strftime(date_format=str(year)+'-%m-%d')\n",
    "    df_tmp['rel_date'] = pd.to_datetime(df_tmp['rel_date'],format='%Y-%m-%d')\n",
    "    df_tmp.index=df_tmp['rel_date']\n",
    "    df_tmp=df_tmp.merge(df_1d.loc[st:ed,['LE/ET']], how='inner',left_index=True, right_index=True)\n",
    "    #after this merge is done we can rename the GWS column\n",
    "    df_tmp.rename(columns={GWS_key:'GWS_diff'},inplace=True)\n",
    "    #print(df_tmp.columns)\n",
    "    df_1d_seq = pd.concat([df_1d_seq,df_tmp],axis='index') #vertical join, along index\n",
    "    df_1d_seq = df_1d_seq.dropna() #remove entries where there are at least one nan\n",
    "\n",
    "df_1d_seq=df_1d_seq.resample('7D').mean()\n",
    "df_1d_seq=df_1d_seq.dropna()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_1d_seq['GWS_diff'],df_1d_seq['LE/ET'],color='b',s=5)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_1d_seq['GWS_diff'],df_1d_seq['LE/ET'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "\n",
    "ax.set_xlabel('GW change since april 1st of that year [cm]')\n",
    "ax.set_ylabel(r'$r_{lim}$ [-]')\n",
    "#ax.set_xlim(-5,90)\n",
    "#ax.set_ylim(0,1.2)\n",
    "fig.suptitle(r'$r_{lim}$ over groundwater change since april 1st (weekly average, no rainy days)')\n",
    "ax.set_title('intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "#df_1d_seq.head(50)\n",
    "\n",
    "\n",
    "    \n",
    "#df_GWS_multi7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a97f81-9b3e-4cef-ba41-8c3a6034bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
    "\n",
    "#sequential processing of days since rain\n",
    "#df_GWS_multi7d=df_GWS_multi.iloc[:,2:].resample('7D').mean()\n",
    "\n",
    "df_1d=pd.DataFrame()\n",
    "\n",
    "df_1d=df_tmp3h.resample('1D').mean()\n",
    "\n",
    "#df_1d=df_tmp30m.resample('1D').mean()\n",
    "#df_1d['P(mast)']=df_tmp30m['P(mast)'].resample('1D').sum() #precip needs to be sum, not mean.\n",
    "\n",
    "###days since rain counting\n",
    "df_1d['index_shift'] = df_1d.index.shift()\n",
    "df_1d['timestep']=df_1d['index_shift']-df_1d.index\n",
    "df_1d['is_1d']=df_1d['timestep']==pd.Timedelta(days=1)\n",
    "df_1d['days_since_rain']=np.nan #init the new column for assignment\n",
    "\n",
    "counter=0\n",
    "for index, row in df_1d.iterrows():\n",
    "    if row['P(mast)']!=0.0: #if rain isnt zero, reset counting to 0\n",
    "        counter=0\n",
    "        df_1d.loc[index,'days_since_rain']=counter\n",
    "    else: #rain is zero, keep counting up\n",
    "        if row['is_1d']: #if true, then timedelta is 1 and you keep going, otherwise there's a gap in data and rest to 0\n",
    "            counter=counter+1\n",
    "            df_1d.loc[index,'days_since_rain']=counter\n",
    "            #if index.strftime(date_format='%m-%d')=='04-01': #if it's april first, reset counter\n",
    "            #    counter=0\n",
    "            #    df_1d.loc[index,'days_since_rain']=counter\n",
    "            #else: #otherwise count up\n",
    "                        \n",
    "        else: #there is a gap in the data, previous entry not one day before, reset counter to 0\n",
    "            counter=0\n",
    "            df_1d.loc[index,'days_since_rain']=counter\n",
    "            \n",
    "###days since rain counting end\n",
    "\n",
    "\n",
    "#filter out rainy days\n",
    "df_1d=df_1d.loc[df_1d['P(mast)']==0.0]\n",
    "df_1d=df_1d.loc[df_1d['RD']==0.0] #knmi rain data\n",
    "\n",
    "df_1d['LE/ET']=df_1d['LE']/df_1d['ET']\n",
    "df_1d=df_1d.loc[df_1d['LE/ET']<2.0]\n",
    "\n",
    "df_1d_seq=pd.DataFrame() #sequential dataframe\n",
    "\n",
    "for year in range(2001,2020):\n",
    "    \n",
    "    st=str(year)+\"-04-01\"\n",
    "    ed=str(year)+\"-09-30\"\n",
    "    st2=\"2000-04-01\" #due to df_GWS_multi being indexed to the year 2000, we need extra set of st and ed\n",
    "    ed2=\"2000-09-30\"\n",
    "    GWS_key='depth_'+str(year)+'_diff' #the column name to ask for\n",
    "    df_tmp=pd.DataFrame()\n",
    "    df_tmp[GWS_key]=df_GWS_multi.loc[st2:ed2,[GWS_key]]\n",
    "    df_tmp['rel_date'] = df_tmp.index.strftime(date_format=str(year)+'-%m-%d')\n",
    "    df_tmp['rel_date'] = pd.to_datetime(df_tmp['rel_date'],format='%Y-%m-%d')\n",
    "    df_tmp.index=df_tmp['rel_date']\n",
    "    df_tmp=df_tmp.merge(df_1d.loc[st:ed,['LE/ET','days_since_rain','timestep']], how='inner',left_index=True, right_index=True)\n",
    "    #print(df_tmp)\n",
    "    #after this merge is done we can rename the GWS column\n",
    "    df_tmp.rename(columns={GWS_key:'GWS_diff'},inplace=True)\n",
    "    #print(df_tmp.columns)\n",
    "    df_1d_seq = pd.concat([df_1d_seq,df_tmp],axis='index') #vertical join, along index\n",
    "    df_1d_seq = df_1d_seq.dropna() #remove entries where there are at least one nan\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_1d_seq['days_since_rain'],df_1d_seq['LE/ET'],color='b',s=5)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_1d_seq['days_since_rain'],df_1d_seq['LE/ET'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=-1, c='r',linestyle='dashed',label='1:-1')\n",
    "\n",
    "ax.set_xlabel('days since rain')\n",
    "ax.set_ylabel('fstr')\n",
    "#ax.set_xlim(-5,90)\n",
    "#ax.set_ylim(0,1.2)\n",
    "fig.suptitle('fstr over days since rain')\n",
    "ax.set_title('intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#df_1d.head(50)\n",
    "\n",
    "#df_GWS_multi7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d45b23-90b9-4fb0-a68f-fbeaf4b9da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2498fbe-9198-432a-b9a7-f2085782a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "\n",
    "#sequential processing of days since rain\n",
    "#df_GWS_multi7d=df_GWS_multi.iloc[:,2:].resample('7D').mean()\n",
    "\n",
    "df_1d=pd.DataFrame()\n",
    "\n",
    "df_1d=df_tmp3h.resample('1D').mean()\n",
    "\n",
    "#df_1d=df_tmp30m.resample('1D').mean()\n",
    "#df_1d['P(mast)']=df_tmp30m['P(mast)'].resample('1D').sum() #precip needs to be sum, not mean.\n",
    "\n",
    "###days since rain counting\n",
    "df_1d['index_shift'] = df_1d.index.shift()\n",
    "df_1d['timestep']=df_1d['index_shift']-df_1d.index\n",
    "df_1d['is_1d']=df_1d['timestep']==pd.Timedelta(days=1)\n",
    "df_1d['days_since_rain']=np.nan #init the new column for assignment\n",
    "\n",
    "counter=0\n",
    "for index, row in df_1d.iterrows():\n",
    "    if row['P(mast)']!=0.0: #if rain isnt zero, reset counting to 0\n",
    "        counter=0\n",
    "        df_1d.loc[index,'days_since_rain']=counter\n",
    "    else: #rain is zero, keep counting up\n",
    "        if row['is_1d']: #if true, then timedelta is 1 and you keep going, otherwise there's a gap in data and rest to 0\n",
    "            counter=counter+1\n",
    "            df_1d.loc[index,'days_since_rain']=counter\n",
    "            #if index.strftime(date_format='%m-%d')=='04-01': #if it's april first, reset counter\n",
    "            #    counter=0\n",
    "            #    df_1d.loc[index,'days_since_rain']=counter\n",
    "            #else: #otherwise count up\n",
    "                        \n",
    "        else: #there is a gap in the data, previous entry not one day before, reset counter to 0\n",
    "            counter=0\n",
    "            df_1d.loc[index,'days_since_rain']=counter\n",
    "            \n",
    "###days since rain counting end\n",
    "\n",
    "\n",
    "#filter out rainy days\n",
    "df_1d=df_1d.loc[df_1d['P(mast)']==0.0]\n",
    "df_1d=df_1d.loc[df_1d['RD']==0.0] #knmi rain data\n",
    "\n",
    "df_1d['LE/ET']=df_1d['LE']/df_1d['ET']\n",
    "df_1d=df_1d.loc[df_1d['LE/ET']<2.0]\n",
    "\n",
    "df_1d_seq=pd.DataFrame() #sequential dataframe\n",
    "\n",
    "for year in range(2001,2020):\n",
    "    \n",
    "    st=str(year)+\"-04-01\"\n",
    "    ed=str(year)+\"-09-30\"\n",
    "    st2=\"2000-04-01\" #due to df_GWS_multi being indexed to the year 2000, we need extra set of st and ed\n",
    "    ed2=\"2000-09-30\"\n",
    "    GWS_key='depth_'+str(year)+'_diff' #the column name to ask for\n",
    "    df_tmp=pd.DataFrame()\n",
    "    df_tmp[GWS_key]=df_GWS_multi.loc[st2:ed2,[GWS_key]]\n",
    "    df_tmp['rel_date'] = df_tmp.index.strftime(date_format=str(year)+'-%m-%d')\n",
    "    df_tmp['rel_date'] = pd.to_datetime(df_tmp['rel_date'],format='%Y-%m-%d')\n",
    "    df_tmp.index=df_tmp['rel_date']\n",
    "    df_tmp=df_tmp.merge(df_1d.loc[st:ed,['LE/ET','days_since_rain','timestep']], how='inner',left_index=True, right_index=True)\n",
    "    #print(df_tmp)\n",
    "    #after this merge is done we can rename the GWS column\n",
    "    df_tmp.rename(columns={GWS_key:'GWS_diff'},inplace=True)\n",
    "    #print(df_tmp.columns)\n",
    "    df_1d_seq = pd.concat([df_1d_seq,df_tmp],axis='index') #vertical join, along index\n",
    "    df_1d_seq = df_1d_seq.dropna() #remove entries where there are at least one nan\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_1d_seq['d_since_int']=df_1d_seq['days_since_rain'].astype(int)\n",
    "\n",
    "###\n",
    "#ax.scatter(df_1d_seq['days_since_rain'],df_1d_seq['LE/ET'],color='b',s=5)\n",
    "\n",
    "sns.boxplot(data=df_1d_seq, x='d_since_int', y='LE/ET', ax=ax, gap=0.5, fliersize=0.01 )\n",
    "\n",
    "#sns.plot(data=df_1d_seq,ax=ax)\n",
    "\n",
    "ax.set_xlabel('days since rain')\n",
    "ax.set_ylabel(r'r$_{lim} [-]$')\n",
    "#ax.set_xlim(-5,90)\n",
    "#ax.set_xlim(-1,22.5)\n",
    "fig.suptitle(r'r$_{lim}$ over days since rain')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_1d_seq.head(5)\n",
    "\n",
    "#df_GWS_multi7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cea47-8e7a-4707-b2d7-ad86fc310c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof of concept snippet SHIFTING\n",
    "e=df_tmp30m.loc['2003-01-01':'2003-01-15',['P(mast)']]\n",
    "e=e.resample('3H').sum()\n",
    "#e['event']=e.any(e['P(mast)']!=0.0)\n",
    "\n",
    "e['time_since']=np.nan\n",
    "counter=0\n",
    "#e['P(mast)_shift']=e['P(mast)'].shift() #no need for this\n",
    "e['index_shift']=e.index.shift()\n",
    "e['timestep']=e['index_shift']-e.index\n",
    "e['is_30m']=e['timestep']==pd.Timedelta(hours=3)\n",
    "\n",
    "for index, row in e.iterrows():\n",
    "    if row['P(mast)']!=0.0: #if rain isnt zero, reset counting to 0\n",
    "        counter=0\n",
    "        e.loc[index,'time_since']=counter\n",
    "    else: #rain is zero, keep counting up\n",
    "        counter=counter+1\n",
    "        e.loc[index,'time_since']=counter\n",
    "\n",
    "e.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8de16-27e8-434d-8de7-a449ae7144ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proof of concept snippet\n",
    "e=df_tmp30m.loc['2003-01-01':'2003-01-15',['P(mast)']]\n",
    "e=e.resample('3H').sum()\n",
    "#e['event']=e.any(e['P(mast)']!=0.0)\n",
    "\n",
    "e['time_since']=np.nan\n",
    "counter=0\n",
    "\n",
    "for index, row in e.iterrows():\n",
    "    if row['P(mast)']==0.0:\n",
    "        counter=counter+1\n",
    "        e.loc[index,'time_since']=counter\n",
    "    else:\n",
    "        counter=0\n",
    "        e.loc[index,'time_since']=counter\n",
    "\n",
    "#e.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e74afc-910d-4ace-8f2a-71b9caf03092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_since=\n",
    "df_tmp3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f3adf-5e65-4e7b-84dc-a8e4456b0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=pd.DataFrame()\n",
    "df_tmp=df_GWS_multi.loc[\"2000-04-01\":\"2000-09-30\",['depth_'+str(2002)+'_diff']]\n",
    "df_tmp['str_date'] = df_tmp.index.strftime(date_format=str(2002)+'-%m-%d')\n",
    "df_tmp.index=df_tmp['str_date']\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab4558-ac1d-4506-94ec-043e5f11bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old method\n",
    "#new location put 88\n",
    "dir = '../Dinoloket_2024-01-20/Grondwaterstanden_Put/B32F0088001_1_edit.csv'\n",
    "df_GWS=pd.read_csv(dir,sep=\",\",index_col=False)\n",
    "df_GWS=df_GWS.drop(['Locatie','Filternummer','Bijzonderheid','Opmerking'], axis=1)\n",
    "#df_GWS['Peildatum']=df_GWS['Peildatum']+\" 12:00\"\n",
    "df_GWS['datetime']=pd.to_datetime(df_GWS['Peildatum'], dayfirst=True, format='mixed')\n",
    "df_GWS.index = df_GWS['datetime']\n",
    "df_GWS=df_GWS.drop(['Peildatum','datetime'], axis=1)\n",
    "st=\"2001-01-01\"\n",
    "ed=\"2019-12-30\"\n",
    "df_GWS=df_GWS.loc[st:ed]\n",
    "avg_GWS = df_GWS['Stand (cm t.o.v. MV)'].mean()\n",
    "df_GWS['anom'] = df_GWS.loc[st:ed,'Stand (cm t.o.v. MV)']-avg_GWS\n",
    "\n",
    "df_GWS_7d=df_GWS.resample('7D').interpolate()\n",
    "avg_GWS_7d = df_GWS_7d['Stand (cm t.o.v. MV)'].mean()\n",
    "df_GWS_7d['anom']=df_GWS_7d.loc[st:ed,'Stand (cm t.o.v. MV)']-avg_GWS_7d\n",
    "df_GWS_7d.index=df_GWS_7d.index.astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb16af5-c0b9-4443-97d7-ceb46ef6e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old plot\n",
    "df_tmp30m=pd.DataFrame()\n",
    "df_tmp30m['ET']=df_ET['ET_VPD']\n",
    "df_tmp30m=df_tmp30m.dropna()\n",
    "\n",
    "df_LE=df_Comb['LE'].loc[df_Comb['LE']>=0]\n",
    "df_tmp30m=df_tmp30m.merge(df_LE, how='inner',left_index=True, right_index=True)\n",
    "df_1d=df_tmp30m.resample('1D').sum()\n",
    "\n",
    "df_1d['LE/ET']=df_1d['LE']/df_1d['ET']\n",
    "df_1d=df_1d.loc[df_1d['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "st=\"2011-04-01\"\n",
    "ed=\"2011-09-30\"\n",
    "\n",
    "\n",
    "df_1d=df_1d.merge(df_GWS['anom'], how='inner',left_index=True, right_index=True)\n",
    "#df_1d=df_1d.merge(dfGWS['anom'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_1d['anom'],df_1d['LE/ET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27276818-dfba-4efb-87ff-8eef8d28f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['anom'],left_index=True, right_index=True,direction='backward')\n",
    "#df_1d=df_1d.merge(dfGWS['anom'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_tmp7d_1['anom'],df_tmp7d_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_title('weekly average fstr (only 9:00-15:00, no rainy days) over groundwater anomaly')\n",
    "#fstr over groundwater change since april 1st (weekly average)'\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('groundwater anomaly (cm) (positive value means deeper)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "df_tmp7d_1=df_tmp7d_1.dropna()\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp7d_1['anom'], df_tmp7d_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b250ad-6392-4fee-9da1-5d7cb623489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "#df_1d=df_1d.merge(dfGWS['anom'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_tmp7d_1['Stand (cm t.o.v. MV)'],df_tmp7d_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_title('7-day average fstr (only 9:00-15:00, no rainy days) over groundwater depth')\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('groundwater depth (cm) (positive value means deeper)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp7d_1['Stand (cm t.o.v. MV)'], df_tmp7d_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfababb-0347-40f7-b767-76a4b4b345b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "#df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "\n",
    "\n",
    "df_tmp7d_1=df_tmp7d.merge(df_soil_7d['SM-003'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_tmp7d_1['SM-003'],df_tmp7d_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1.2)\n",
    "ax.set_title('7-day average fstr (only 9:00-15:00, no rainy days) over Soil moisture (at 3cm)')\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('soil moisture at 3cm depth (% volume)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "df_tmp_7d_1=df_tmp_7d_1.dropna()\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp7d_1['SM-003'], df_tmp7d_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d4d49-7fc0-4aba-bf69-3175de9109ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "#df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "\n",
    "\n",
    "df_tmp7d_1=df_tmp7d.merge(df_soil_7d['SM-Lit'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_tmp7d_1['SM-Lit'],df_tmp7d_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1.2)\n",
    "ax.set_title('7-day average fstr (only 9:00-15:00, no rainy days) over Soil moisture (Litter)')\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('soil moisture at Litter (% volume)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp7d_1['SM-Lit'], df_tmp7d_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a410e-8c7d-400b-9e01-a34f66d0e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil_7d_sm3_mean=df_soil_7d['SM-003'].mean()\n",
    "df_soil_7d_lit_mean=df_soil_7d['SM-Lit'].mean()\n",
    "df_soil_7d['SM-003_anom']=df_soil_7d['SM-003']-df_soil_7d_sm3_mean\n",
    "df_soil_7d['SM-Lit_anom']=df_soil_7d['SM-Lit']-df_soil_7d_lit_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd17a94-6f6c-425f-b927-3cae349581ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "#df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "\n",
    "\n",
    "df_tmp7d_1=df_tmp7d.merge(df_soil_7d['SM-003_anom'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(df_tmp7d_1['SM-003_anom'],df_tmp7d_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1.2)\n",
    "ax.set_title('7-day average fstr (only 9:00-15:00, no rainy days) over Soil moisture Anomaly (3cm depth)')\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('soil moisture anomaly at 3cm depth (% volume)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "df_tmp7d_1=df_tmp7d_1.dropna()\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp7d_1['SM-003_anom'], df_tmp7d_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b91c7-9328-461d-b6af-0f5af11a05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEREEEE\n",
    "SM= pd.read_csv('Soil_moisture.csv')\n",
    "SM['datetime']=pd.to_datetime(SM['datetime'])\n",
    "SM.index=SM['datetime']\n",
    "SM.drop(columns='datetime',inplace=True)\n",
    "#SM has columns SM-003\tSM-020\tSM-050\tSM-100\t'SM_l1' (i.e. 0-50cm)\t'SM_l2' (i.e. 50-100)\n",
    "#and runs from 2005-04-11 00:00:00 2020-12-31 23:30:00 and freq 30 min\n",
    "#SM=SM.resample('7D').mean()\n",
    "SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c3afd-16db-4b0c-bf78-d26a9770b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d19dc-e9c9-4ea5-861b-8cd2e777c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp1dc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaab5dc-7182-49c8-9b8f-33e24baa7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SM_1=SM.reset_index()\n",
    "#df_tmp7d_1=df_tmp7d.reset_index()\n",
    "#SM_1 = pd.concat([SM,df_tmp7d_1],axis=1)\n",
    "SM_1 = SM.resample('D').mean()\n",
    "\n",
    "SM_1 = pd.concat([SM_1,df_tmp1dc_day],axis=1)\n",
    "#SM_1=SM_1.loc[:,['SM_l1','SM_l2','fstr',P]]\n",
    "SM_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893c6d1-f6f0-4def-b48a-d7283e12240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp1dc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973abf9-3119-42fc-9e13-af46216afd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fstr max over 1 day, fstr values can be bigger than 1, day-values (08-18:00) and all\n",
    "df_tmp1d      =pd.read_csv('./fstrOutput/NoRain/fstr_1d.csv')\n",
    "df_tmp1d.index=pd.to_datetime(df_tmp1d['Unnamed: 0'])\n",
    "df_tmp1d.index.name='date'\n",
    "df_tmp1d.drop(columns='Unnamed: 0',inplace=True)\n",
    "df_tmp1d_day  =pd.read_csv('./fstrOutput/NoRain/fstrMax_1d_day.csv')\n",
    "df_tmp1d_day.index=pd.to_datetime(df_tmp1d_day['Unnamed: 0'])\n",
    "df_tmp1d_day.index.name='date'\n",
    "df_tmp1d_day.drop(columns='Unnamed: 0',inplace=True)\n",
    "\n",
    "#fstr max over 1 day, values of fstr are clamped between 0 and 1, day-values (08-18:00) and all\n",
    "df_tmp1dc     =pd.read_csv('./fstrOutput/NoRain/fstr_1d_clamped.csv')\n",
    "df_tmp1dc.index=pd.to_datetime(df_tmp1dc['Unnamed: 0'])\n",
    "df_tmp1dc.index.name='date'\n",
    "df_tmp1dc.drop(columns='Unnamed: 0',inplace=True)\n",
    "df_tmp1dc_day =pd.read_csv('./fstrOutput/NoRain/fstr_1d_clamped_day.csv')\n",
    "df_tmp1dc_day.index=pd.to_datetime(df_tmp1dc_day['Unnamed: 0'])\n",
    "df_tmp1dc_day.index.name='date'\n",
    "df_tmp1dc_day.drop(columns='Unnamed: 0',inplace=True)\n",
    "\n",
    "#fstr max over 1 day, values of fstr are clamped between 0 and 1, day-values (08:00-18:00) only\n",
    "df_tmp1dcm    =pd.read_csv('./fstrOutput/NoRain/fstrMax_1d_clamped_day.csv')\n",
    "df_tmp1dcm.index=pd.to_datetime(df_tmp1dcm['Unnamed: 0'])\n",
    "df_tmp1dcm.index.name='date'\n",
    "df_tmp1dcm.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330ad44-5c5f-4883-8ace-e56807b6a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_1=pd.concat([SM_1,df_tmp1dc_day],axis=1)\n",
    "SM_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6bfb4-a7b0-4796-96ae-398dd246638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "#df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.merge(SM_1['SM_l1'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(SM_1['SM_l1'],SM_1['fstr'],marker='.')\n",
    "\n",
    "#ax.set_ylim(0,1.2)\n",
    "ax.set_xlim(0.02,0.12)\n",
    "\n",
    "ax.set_ylabel(r'$r_{lim}$ daily mean')\n",
    "ax.set_xlabel('daily mean soil moisture (mean of 0-100cm layer) [%])')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "SM_1=SM_1.dropna()\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(SM_1['SM_l1'], SM_1['fstr']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "ax.set_title('daily average r_lim (only 9:00-15:00, no rainy days) over Soil moisture (0-100cm) \\n intercept = 0.656 , slope =  0.885 , R2 = 0.0004 ')\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8875c-5335-4512-9579-b0c28ff4b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault\n",
    "#plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.copy()\n",
    "#df_tmp1d_1=df_tmp1d_1.loc[df_tmp1d_1['LE/ET']<1.0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "#st=\"2011-04-01\"\n",
    "#ed=\"2011-09-30\"\n",
    "\n",
    "#df_GWS_7d['Stand (cm t.o.v. MV)']\n",
    "#df_tmp7d_1=pd.merge_asof(df_tmp7d,df_GWS_7d['Stand (cm t.o.v. MV)'],left_index=True, right_index=True,direction='backward')\n",
    "\n",
    "\n",
    "#df_tmp7d_1=df_tmp7d.merge(SM_1['SM_l1'], how='inner',left_index=True, right_index=True)\n",
    "\n",
    "ax.scatter(SM_1['SM_l2'],SM_1['LE/ET'])\n",
    "\n",
    "ax.set_ylim(0,1.2)\n",
    "ax.set_xlim(0.03,0.12)\n",
    "\n",
    "ax.set_ylabel('fstr 7day mean')\n",
    "ax.set_xlabel('soil moisture layer2 50-100cm (1/100 % volume)')\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "SM_1=SM_1.dropna()\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(SM_1['SM_l2'], SM_1['LE/ET']) #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "ax.set_title('7-day average fstr (only 9:00-15:00, no rainy days) over Soil moisture (50-100cm) \\n intercept = 0.546 , slope =  2.95 , R2 = 0.00267 ')\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "#ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87600d07-db49-4b1a-bd86-04c815915bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil_7d=df_soil.loc['2001-06-21':'2019-07-25'].resample('7D').mean()#['SM-Lit']\n",
    "df_soil_7d['SM-003'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e162cb4-f497-46dc-98c6-f05722b4182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80a9cc-5f33-418c-9973-45e8ca465434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp7d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7442bf-c42c-4bc0-83ca-bd8d1eca0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil_7d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769e828-92fe-4e27-b682-de587d45771e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d5474-a5a1-47fc-ab71-ccff0515678f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95f578-479f-4322-bb06-297a37b2fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc592d-6b35-452e-b02c-1a678a421bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89ac88-22f8-4981-ad1e-899230376ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 471.85,
   "position": {
    "height": "493.844px",
    "left": "1539.19px",
    "right": "20px",
    "top": "105px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
