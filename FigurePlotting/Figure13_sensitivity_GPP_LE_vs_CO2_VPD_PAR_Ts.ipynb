{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2978442-0a0a-42b2-ac0f-8e6b685580d8",
   "metadata": {},
   "source": [
    "# A-gs model and implementation (simulation CO2 and H2O flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5053646-e207-4e8c-a62e-2a7f70ad0887",
   "metadata": {},
   "source": [
    "## Initialize data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467470b3-2427-4ada-b14f-9ff26922d8ec",
   "metadata": {},
   "source": [
    "### Setup and fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515abf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "Username   = 'Beheerder'\n",
    "years      = range(2001,2020)    #(1997,2021) # Set years to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath   = os.path.join('../')\n",
    "print('datapath is set to %s'%datapath)\n",
    "\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install plotly \n",
    "# !pip install cufflinks\n",
    "#!pip install colorspacious\n",
    "#!pip install seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "#import cufflinks as cf\n",
    "import matplotlib.dates as mdate\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm\n",
    "#from colorspacious import cspace_converter\n",
    "import scipy.stats as stats\n",
    "#cf.go_offline()\n",
    "# cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(datapath,'PythonScripts'))\n",
    "from Loobos_Toolbox import dateparse, dateparse_Gapfilled, Read_LoobosEddFinal, Read_LooStor, Read_LoodatGapfill, Read_Loobos_halfhourly, Read_Loobos_meteo, Read_Loobos_soil, Read_Loobos_profile\n",
    "\n",
    "from Ags_model import runAgs, runAgs2, calc_LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these next two lines are to prevent re-loading the data. If you want to re-load data, instead comment them out\n",
    "if not 'progress' in globals(): progress = list()\n",
    "if not 'dataloaded' in progress:\n",
    "  # Read files\n",
    "    df_EC           = Read_LoobosEddFinal    (years,datapath)\n",
    "    df_Stor         = Read_LooStor           (years,datapath)\n",
    "    df_Comb         = Read_LoodatGapfill     (years,datapath)\n",
    "    df_NEE          = Read_Loobos_halfhourly (years,datapath)\n",
    "    df_meteo        = Read_Loobos_meteo      (years,datapath)\n",
    "    df_soil         = Read_Loobos_soil       (years,datapath) \n",
    "    df_profile      = Read_Loobos_profile    (years,datapath)\n",
    "    progress.append('dataloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94f06d-3b56-4ade-89ae-00b484fb8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make filter for GPP orginial data and not gapfilled\n",
    "#General filters\n",
    "I = ((df_Comb['GPP_fqc']==0)&(df_meteo['PAR']>0))\n",
    "#t = df_profile.index                                          \n",
    "#time = (t < np.datetime64('2013-05-08')) | (t > np.datetime64('2013-06-01'))\n",
    "\n",
    "# Filter for CO2 data\n",
    "CO2 = (df_profile['CO2level1'] > 300)\n",
    "\n",
    "# Filter for L(o)corr data\n",
    "Locorr= (df_meteo['L(o)corr']>0) \n",
    "\n",
    "# Filter for VPD data\n",
    "VPD = (df_Comb['VPD']>=0)\n",
    "\n",
    "# Filter for U-star\n",
    "Ustar = (df_EC['U-star']>=0)\n",
    "\n",
    "# Combine all filters\n",
    "filter = I & CO2 & Locorr & VPD & Ustar\n",
    "\n",
    "#Column 'CO2' is input from df_profile\n",
    "#df_profile_CO2 = df_profile[CO2]\n",
    "#df_profile_filter = df_profile_CO2[I]\n",
    "df_profile_filter = df_profile[filter]\n",
    "\n",
    "#Column 'L(o)corr' and 'PAR' are inputs from df_meteo\n",
    "#df_meteo_CO2 = df_meteo[CO2]\n",
    "#df_meteo_filter = df_meteo_CO2[I]\n",
    "df_meteo_filter = df_meteo[filter]\n",
    "\n",
    "#Columns 'VPD' and 'Tair' are inputs from df_Comb\n",
    "#df_Comb_CO2 = df_Comb[CO2]\n",
    "#df_Comb_filter = df_Comb_CO2[I]\n",
    "df_Comb_filter = df_Comb[filter]\n",
    "\n",
    "# Columns 'Mea_Windsp' and 'U-star' are inputs from df_EC\n",
    "#df_EC_CO2 = df_EC[CO2]\n",
    "#df_EC_filter = df_EC_CO2[I]\n",
    "df_EC_filter = df_EC[filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1996767-09d3-441d-b711-cea73a750854",
   "metadata": {},
   "source": [
    "### Run A-gs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run A-gs model\n",
    "fstr=0.8\n",
    "an_final,an_umol,rs, ra, Ts_C = runAgs2(df_profile_filter,df_Comb_filter,df_meteo_filter,df_EC_filter,fstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0753ef-8f5b-4b55-83db-ad31419a0e53",
   "metadata": {},
   "source": [
    "## Calcuate ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d717-ea63-477c-9c43-8a29262f3143",
   "metadata": {},
   "source": [
    "### Assemble dataframe 'df_ET' that will hold output and fill with inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065217e-ea3f-4cfc-97af-76ad200b8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET = pd.concat([df_meteo['L(o)'],df_meteo['Te-L(o)'],df_profile['Pressure'],df_Comb['VPD'],df_Comb['rH'],df_meteo['P(mast)']],axis=1,sort=False)\n",
    "#convert Pressure from hPa to kPa \n",
    "df_ET['p_kPa']=df_ET['Pressure']/10\n",
    "df_ET['VPD_adj']=df_ET['VPD'].loc[df_ET['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "df_ET['VPD_adj']=df_ET['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f94f14-69d7-4d8a-a720-5531d86ec058",
   "metadata": {},
   "source": [
    "### calculate ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833759c4-4fe4-4fee-bffb-472e0923e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ETframe(rs_series):\n",
    "    df_ET = pd.concat([df_meteo['L(o)'],df_meteo['Te-L(o)'],df_profile['Pressure'],df_Comb['VPD'],df_Comb['rH'],df_meteo['P(mast)']],axis=1,sort=False)\n",
    "    #convert Pressure from hPa to kPa \n",
    "    df_ET['p_kPa']=df_ET['Pressure']/10\n",
    "    df_ET['VPD_adj']=df_ET['VPD'].loc[df_ET['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "    df_ET['VPD_adj']=df_ET['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa\n",
    "    df_ET['rs']=rs_series.to_frame(name=\"rs\")\n",
    "    df_ET['ra']=ra.to_frame(name=\"ra\")\n",
    "    return df_ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d53c8-f280-4a9f-a8c8-a4caf646e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET=init_ETframe(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b44ff-e849-4e28-83fa-40add5c2f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ET=calc_LE(df_ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868d56d-8dbe-44fd-a44d-a92bcfdc2c98",
   "metadata": {},
   "source": [
    "## Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8859bf-ea71-409e-85b1-ab61bcd87d6e",
   "metadata": {},
   "source": [
    "### CO2 flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2211734-c58e-4cf5-a18d-e726977c33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "st='2018-05-01 00:00'\n",
    "ed='2018-08-30 00:00'\n",
    "time_s=\"9:00\"\n",
    "time_e=\"18:00\"\n",
    "\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean().between_time(time_s,time_e)\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean().between_time(time_s,time_e)\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean().between_time(time_s,time_e)\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean().between_time(time_s,time_e)\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "#Ts_data=Ts_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "an_data=an_umol.loc[start:end].resample('3H').mean().between_time(time_s,time_e)\n",
    "an_data=an_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "an_data=an_data.rename('an_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['an_data']=an_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['an_data']=an_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['an_data']=an_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['an_data']=an_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of An to VPD, CO2, PAR, and Ts. \\n (2008-2017 during growth seasons May-Oct, 3-hour averages for 9:00-18:00)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['an_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p1a=ax1.scatter(df_tmp1.loc[st:ed,'VPD'],df_tmp1.loc[st:ed,'an_data'],marker='x',c='black') #scatter(x,y)\n",
    "ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['an_data'],marker='o',c=df_tmp2.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p2a=ax2.scatter(df_tmp2.loc[st:ed,'CO2level1'],df_tmp2.loc[st:ed,'an_data'],marker='x',c='black',label='2018') #scatter(x,y)\n",
    "ax2.set_ylim(0,35)\n",
    "ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p3=ax3.scatter(df_tmp3['PAR'],df_tmp3['an_data'],marker='o',c=df_tmp3.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p3a=ax3.scatter(df_tmp3.loc[st:ed,'PAR'],df_tmp3.loc[st:ed,'an_data'],marker='x',c='black') #scatter(x,y)\n",
    "ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p4=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['an_data'],marker='o',c=df_tmp4.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p4a=ax4.scatter(df_tmp4.loc[st:ed,'Ts_data'],df_tmp4.loc[st:ed,'an_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'Tsurface [deg C]')\n",
    "ax4.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5d373-849a-4db2-893f-3f653e266f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "Ts_data=Ts_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "an_data=an_umol.loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "an_data=an_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "an_data=an_data.rename('an_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['an_data']=an_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['an_data']=an_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['an_data']=an_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['an_data']=an_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of GPP to VPD, CO2, PAR, and T_surface. \\n (2001-2020 during growth seasons Apr-Sep, 3-hour averages)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['an_data'],marker='o',c=df_tmp1.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['an_data'],marker='o',c=df_tmp1.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "ax2.set_ylim(0,35)\n",
    "ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p1=ax3.scatter(df_tmp3['PAR'],df_tmp3['an_data'],marker='o',c=df_tmp1.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p1=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['an_data'],marker='o',c=df_tmp1.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'T_surface [deg C]')\n",
    "ax4.set_ylabel(r'An [$\\mu molm^{-2}s^{-1}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5331a-f307-465d-b87d-4823234a14d4",
   "metadata": {},
   "source": [
    "### H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7c56b-b822-4767-b984-6509a36fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "Ts_data=Ts_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "LE_data=df_ET.loc[start:end,'ET_VPD'].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "LE_data=LE_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "LE_data=LE_data.rename('LE_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['LE_data']=LE_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['LE_data']=LE_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['LE_data']=LE_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['LE_data']=LE_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of LE to VPD, CO2, PAR, and T_surface. \\n (2001-2020 during growth seasons Apr-Sep,, 3-hour averages)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['LE_data'],marker='o',c=df_tmp1.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "#ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['LE_data'],marker='o',c=df_tmp2.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "#ax2.set_ylim(0,35)\n",
    "#ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p1=ax3.scatter(df_tmp3['PAR'],df_tmp3['LE_data'],marker='o',c=df_tmp3.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "#ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p1=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['LE_data'],marker='o',c=df_tmp4.index.hour,s=0.7,cmap='viridis') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'T_surface [deg C]')\n",
    "ax4.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22c43c-1378-4c2b-a903-2e59d6817687",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "st='2018-05-01 00:00'\n",
    "ed='2018-08-30 00:00'\n",
    "time_s=\"9:00\"\n",
    "time_e=\"18:00\"\n",
    "\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean().between_time(time_s, time_e)\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean().between_time(time_s, time_e)\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean().between_time(time_s, time_e)\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean().between_time(time_s, time_e)\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "#Ts_data=Ts_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "LE_data=df_ET.loc[start:end,'ET_VPD'].resample('3H').mean().between_time(time_s, time_e)\n",
    "LE_data=LE_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "LE_data=LE_data.rename('LE_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['LE_data']=LE_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['LE_data']=LE_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['LE_data']=LE_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['LE_data']=LE_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of LE to VPD, CO2, PAR, and Ts. \\n (2008-2017 during growth seasons May-Oct, 3-hour averages for 9:00-18:00)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['LE_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p1a=ax1.scatter(df_tmp1.loc[st:ed,'VPD'],df_tmp1.loc[st:ed,'LE_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['LE_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p2a=ax2.scatter(df_tmp2.loc[st:ed,'CO2level1'],df_tmp1.loc[st:ed,'LE_data'],marker='x',c='black',label='2018') #scatter(x,y)\n",
    "#ax2.set_ylim(0,35)\n",
    "#ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p3=ax3.scatter(df_tmp3['PAR'],df_tmp3['LE_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p3a=ax3.scatter(df_tmp3.loc[st:ed,'PAR'],df_tmp1.loc[st:ed,'LE_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p4=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['LE_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p4a=ax4.scatter(df_tmp4.loc[st:ed,'Ts_data'],df_tmp1.loc[st:ed,'LE_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'Tsurface [deg C]')\n",
    "ax4.set_ylabel(r'LE [$Wm^{-2}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9314a8a-9e42-44c8-b226-c9aecb62c322",
   "metadata": {},
   "source": [
    "## rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9f072-5207-4486-8a40-6ab685c94c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean().between_time(\"9:00\", \"18:00\")\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean().between_time(\"9:00\", \"18:00\")\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean().between_time(\"9:00\", \"18:00\")\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    " \n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean().between_time(\"9:00\", \"18:00\")\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "rs_data=rs.loc[start:end].resample('3H').mean().between_time(\"9:00\", \"18:00\")\n",
    "rs_data=rs_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "rs_data=rs_data.rename('rs_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['rs_data']=rs_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['rs_data']=rs_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['rs_data']=rs_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['rs_data']=rs_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of rs to VPD, CO2, PAR, and Ts. \\n (2008-2017 during growth seasons May-Oct, 3-hour averages between 9:00-18:00)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['rs_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "#ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'rs [$Wm^{-2}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['rs_data'],marker='o',c=df_tmp2.index.hour,cmap='viridis') #scatter(x,y)\n",
    "#ax2.set_ylim(0,35)\n",
    "#ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p1=ax3.scatter(df_tmp3['PAR'],df_tmp3['rs_data'],marker='o',c=df_tmp3.index.hour,cmap='viridis') #scatter(x,y)\n",
    "#ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p1=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['rs_data'],marker='o',c=df_tmp4.index.hour,cmap='viridis') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'Tsurface [deg C]')\n",
    "ax4.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcadf2-ec6b-4bd9-9efb-0c31691c161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2008-05-01 00:00'\n",
    "end='2018-08-30 00:00'\n",
    "st='2018-05-01 00:00'\n",
    "ed='2018-08-30 00:00'\n",
    "#time_s=\"9:00\"\n",
    "#time_e=\"18:00\"\n",
    "\n",
    "sim_data_VPD=df_Comb_filter.loc[start:end,'VPD'].resample('3H').mean().between_time(\"9:00\", \"15:00\")\n",
    "sim_data_VPD=sim_data_VPD.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_CO2=df_profile_filter.loc[start:end,'CO2level1'].resample('3H').mean().between_time(\"9:00\", \"15:00\")\n",
    "sim_data_CO2=sim_data_CO2.dropna() #eliminate NaN entries created by the .loc slice\n",
    "sim_data_PAR=df_meteo_filter.loc[start:end,'PAR'].resample('3H').mean().between_time(\"9:00\", \"15:00\")\n",
    "sim_data_PAR=sim_data_PAR.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "Ts_data=Ts_C.loc[start:end].resample('3H').mean().between_time(\"9:00\", \"15:00\")\n",
    "Ts_data=Ts_data.rename('Ts_data') #turn into a named series so it works with df.merge() properly\n",
    "Ts_data=Ts_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "\n",
    "rs_data=rs.loc[start:end].resample('3H').mean().between_time(\"9:00\", \"15:00\")\n",
    "rs_data=rs_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "rs_data=rs_data.rename('rs_data') #turn into a named series so it works with df.merge() properly\n",
    "\n",
    "\n",
    "df_tmp1 = pd.DataFrame()\n",
    "df_tmp1['rs_data']=rs_data\n",
    "df_tmp1=df_tmp1.merge(sim_data_VPD, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2 = pd.DataFrame()\n",
    "df_tmp2['rs_data']=rs_data\n",
    "df_tmp2=df_tmp2.merge(sim_data_CO2, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp3 = pd.DataFrame()\n",
    "df_tmp3['rs_data']=rs_data\n",
    "df_tmp3=df_tmp3.merge(sim_data_PAR, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp4 = pd.DataFrame()\n",
    "df_tmp4['rs_data']=rs_data\n",
    "df_tmp4=df_tmp4.merge(Ts_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "fig.suptitle('Sensitivity of rs to VPD, CO2, PAR, and Ts. \\n (2008-2017 during growth seasons May-Oct, 3-hour averages between 9:00-18:00)')\n",
    "\n",
    "p1=ax1.scatter(df_tmp1['VPD'],df_tmp1['rs_data'],marker='o',c=df_tmp1.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p1a=ax1.scatter(df_tmp1.loc[st:ed,'VPD'],df_tmp1.loc[st:ed,'rs_data'],marker='x',c='black',label='2018') #scatter(x,y)\n",
    "#ax1.set_ylim(0,35)\n",
    "ax1.set_xlim(-2,40)\n",
    "ax1.set_xlabel('VPD [hPa]')\n",
    "ax1.set_ylabel(r'rs [$Wm^{-2}$]')\n",
    "ax1.set_title('VPD')\n",
    "\n",
    "p2=ax2.scatter(df_tmp2['CO2level1'],df_tmp2['rs_data'],marker='o',c=df_tmp2.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p2a=ax2.scatter(df_tmp2.loc[st:ed,'CO2level1'],df_tmp2.loc[st:ed,'rs_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax2.set_ylim(0,35)\n",
    "#ax2.set_xlim(370,500)\n",
    "ax2.set_xlabel('CO2 [ppm]')\n",
    "ax2.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax2.set_title('CO2')\n",
    "\n",
    "p3=ax3.scatter(df_tmp3['PAR'],df_tmp3['rs_data'],marker='o',c=df_tmp3.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p3a=ax3.scatter(df_tmp3.loc[st:ed,'PAR'],df_tmp3.loc[st:ed,'rs_data'],marker='x',c='black') #scatter(x,y)\n",
    "#ax3.set_ylim(0,35)\n",
    "#ax3.set_xlim(-2,40)\n",
    "ax3.set_xlabel(r'PAR [Wm-2]')\n",
    "ax3.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax3.set_title('PAR')\n",
    "\n",
    "p4=ax4.scatter(df_tmp4['Ts_data'],df_tmp4['rs_data'],marker='o',c=df_tmp4.index.hour,cmap='viridis') #scatter(x,y)\n",
    "p4a=ax4.scatter(df_tmp4.loc[st:ed,'Ts_data'],df_tmp4.loc[st:ed,'rs_data'],marker='x',size=0.1,c='black') #scatter(x,y)\n",
    "#ax4.set_ylim(0,35)\n",
    "#ax4.set_xlim(-20,35)\n",
    "ax4.set_xlabel(r'Tsurface [deg C]')\n",
    "ax4.set_ylabel(r'rs [$sm^{-1}$]')\n",
    "ax4.set_title('Ts')\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.subplots_adjust(top=0.80) #fix the top margin text overlap  \n",
    "#cbar=plt.colorbar(p1,ax=ax)\n",
    "#cbar.ax.set_ylabel('Hour')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(p1, cax=cbar_ax)\n",
    "cbar_ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58badc-6f69-41a3-ace1-c7243975a101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c0ac3e-dbf0-4d94-ba47-e1897fe7fee5",
   "metadata": {},
   "source": [
    "#### quick check R2 for different months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ede45-5b1f-425a-bce1-63ba76a5fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "        \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "        \n",
    "        sim_data=an_umol.loc[an_umol>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['GPP_f'].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        df_tmp = pd.DataFrame()\n",
    "        df_tmp['sim_data']=sim_data\n",
    "        \n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['GPP_f'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),' R2: {:.3f}'.format(r_value**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc463c-0db0-4905-8e14-acc8f405d020",
   "metadata": {},
   "source": [
    "### H2O flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4975a4-4f67-4791-bec3-69061fd4ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def p_dailysum(df):\n",
    "#    for idx,row in df.iterrows():\n",
    "#        #calc precipitation sum from 00:00 to 23:59\n",
    "#        start_day=np.datetime64(str(idx.date())+ ' 00:00')\n",
    "#        end_day=np.datetime64(str(idx.date())+ ' 23:30')\n",
    "#        df.loc[idx,'daily_prec']=df.loc[start_day:end_day ,'P(mast)'].sum() #iloc[row, column]\n",
    "#return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdc8eb-9d91-4d63-be16-a3181941937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old way, deprecated (takes long due to .iterrows() )\n",
    "#df_ET_1=p_dailysum(df_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf194f7b-9be7-494e-9ed2-6bfd232baf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in precipitation last 3h and 24 hour values so it can be used for filtering\n",
    "df_ET_1=df_ET.copy()\n",
    "df_tmp=df_ET_1.groupby(pd.Grouper(freq='D'))[['P(mast)']].sum()\n",
    "df_ET_1['daily_prec']=df_tmp.resample('30min').ffill()\n",
    "df_ET_1['last3h_prec']=df_ET_1['P(mast)'].rolling('3H').sum()\n",
    "df_ET_1['last24h_prec']=df_ET_1['P(mast)'].rolling('24H').sum()\n",
    "df_ET_1['last2day_prec']=df_ET_1['P(mast)'].rolling('48H').sum()\n",
    "df_ET_1['last3day_prec']=df_ET_1['P(mast)'].rolling('72H').sum()\n",
    "#testing\n",
    "df_ET_1.loc['2017-04-15 00:00':'2017-04-30 00:00','daily_prec'].plot()\n",
    "df_ET_1.loc['2017-04-15 00:00':'2017-04-30 00:00','last3h_prec'].plot()\n",
    "df_ET_1.loc['2017-04-15 00:00':'2017-04-30 00:00','last24h_prec'].plot()\n",
    "df_ET_1.loc['2017-04-15 00:00':'2017-04-30 00:00','last3day_prec'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf1845-c2b6-4da2-99e1-4e0604933eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-draw better correlation plot (longer dataset)\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-07-30 00:00'\n",
    "\n",
    "#new filter\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD','last24h_prec','last3day_prec')]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0]\n",
    "sim_data= sim_data.resample('1H').mean()\n",
    "sim_data=sim_data.dropna()\n",
    "\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('1H').mean()#.between_time(\"6:00\", \"9:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "   \n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD'],c=df_tmp.index.hour,cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation of simulated to measured LE. April-Oct 2017, (1hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.set_title('(Only days on which daily  sum of Precip. is 0)')\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8852ef8-a658-4aa3-86a0-8e196f7006cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-draw better correlation plot (plot leaf temperature)\n",
    "start='2017-04-14 00:00'\n",
    "end='2017-08-30 00:00'\n",
    "\n",
    "#new filter\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD','last3day_prec','T_sfc_C')]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0.0]\n",
    "sim_data= sim_data.resample('3H').mean()\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD'],c=df_tmp['T_sfc_C'],cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation of simulated to measured LE. April-Oct 2017, (3hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.set_title('(Only days on which daily  sum of Precip. is 0)')\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Temp [oC]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973cd92-a97c-415d-a33b-983cecc72dfb",
   "metadata": {},
   "source": [
    "#### quick check R2 for different months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342c4ce-2a5e-46ec-a443-55f9b4ee1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what the R2 value is month-wise for certain years\n",
    "#USING THE NEW FUNCTION p_dailysum\n",
    "\n",
    "for year in [2017, 2018]:\n",
    "    for month in [4,5,6,7,8]:\n",
    "         \n",
    "        start='{}-0{}-01 00:00'.format(year, month)\n",
    "        end='{}-0{}-01 00:00'.format(year, month+1)\n",
    "\n",
    "        \n",
    "        sim_data = df_ET_1.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "        sim_data = sim_data.loc[sim_data['last3day_prec']==0.0]\n",
    "        sim_data= sim_data.resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "        measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "        measured_data=measured_data.dropna()\n",
    "        \n",
    "        #df_tmp = pd.DataFrame()\n",
    "        df_tmp=sim_data.copy()\n",
    "        df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "        #print(df_tmp)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "        print('{}-0{}-01 -'.format(year, month),'{}-0{}-01'.format(year, month+1),'Slope:{:.3f} R2: {:.3f}'.format(slope,r_value**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb7b8a-ba39-4a3f-9c85-895bac837881",
   "metadata": {},
   "source": [
    "## first draft sensitivity study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183461c-f090-4047-ada6-ecc48ad5d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second run Ag-s part\n",
    "\n",
    "# Prepare data for Run A-gs model\n",
    "#df_Comb_filter['Tair']\n",
    "df_Comb_filter_1=df_Comb_filter.copy()\n",
    "df_Comb_filter_1['Tair']=df_Comb_filter_1['Tair']+10\n",
    "#df_meteo_filter['L(o)corr']\n",
    "#df_Comb_filter['VPD']\n",
    "#df_meteo_filter['PAR']\n",
    "\n",
    "# Run A-gs model\n",
    "fstr=1.0\n",
    "an_run2,an_umol_run2,rs_run2, ra_run2  = runAgs(df_profile_filter,df_Comb_filter_1,df_meteo_filter,df_EC_filter,fstr)\n",
    "\n",
    "#initialize df_ET\n",
    "df_ET_run2 = pd.concat([df_meteo['L(o)'],df_meteo['Te-L(o)'],df_profile['Pressure'],df_Comb['VPD'],df_Comb['rH'],df_meteo['P(mast)']],axis=1,sort=False)\n",
    "df_ET_run2['p_kPa']=df_ET_run2['Pressure']/10 # from hpa to kpa\n",
    "df_ET_run2['VPD_adj']=df_ET_run2['VPD'].loc[df_ET_run2['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "df_ET_run2['VPD_adj']=df_ET_run2['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa\n",
    "\n",
    "df_ET_run2=calc_LE(df_ET_run2,rs_run2,ra_run2)\n",
    "df_ET_run2['last3day_prec']=df_ET_run2['P(mast)'].rolling('72H').sum()\n",
    "\n",
    "# plot\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-07-30 00:00'\n",
    "\n",
    "#new filter\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0]\n",
    "sim_data= sim_data.resample('1H').mean()\n",
    "sim_data=sim_data.dropna()\n",
    "\n",
    "sim2_data = df_ET_run2.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "sim2_data = sim2_data.loc[sim2_data['last3day_prec']==0]\n",
    "sim2_data= sim2_data.resample('1H').mean()\n",
    "sim2_data=sim2_data.dropna()\n",
    "#sim2_data.rename(columns={'ET_VPD': 'ET_VPD2', 'last3day_prec': 'last3day_prec2'}, inplace=True)\n",
    "\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('1H').mean()\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2=sim2_data.copy()\n",
    "df_tmp2=df_tmp2.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "slope2, intercept2, r_value2, p_value2, std_err2 = stats.linregress(df_tmp2['LE'], df_tmp2['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value2**2)\n",
    "print('slope, intercept:', slope2, intercept2)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD'],marker='o') #scatter(x,y)\n",
    "p2=ax.scatter(df_tmp2['LE'],df_tmp2['ET_VPD'],marker='^') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='black',label='default')\n",
    "ax.axline((0.0,intercept2),slope=slope2,c='black',linestyle='dashed' ,label='Tair+1')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation simulated-measured LE. April-Oct 2017, (1hour mean) \\n default slope = {:.3f}, default R2 = {:.3f} \\n Tair+1 slope = {:.3f}, Tair+1 R2 = {:.3f}'.format(slope,r_value**2,slope2,r_value2**2))\n",
    "#ax.set_title('Tair+1 slope = {:.3f}, Tair+1 R2 = {:.3f}'.format(slope2,r_value2**2))\n",
    "ax.legend(loc='upper left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f62de6-c2eb-42f6-bd70-680caa4bc35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second run Ag-s part\n",
    "\n",
    "# Prepare data for Run A-gs model\n",
    "#df_Comb_filter['Tair']\n",
    "#df_meteo_filter['L(o)corr']\n",
    "#df_Comb_filter['VPD']\n",
    "df_meteo_filter_1=df_meteo_filter.copy()\n",
    "df_meteo_filter_1['PAR']=df_meteo_filter['PAR']*0.9\n",
    "\n",
    "# Run A-gs model\n",
    "fstr=1.0\n",
    "an_run2,an_umol_run2,rs_run2, ra_run2  = runAgs(df_profile_filter,df_Comb_filter,df_meteo_filter_1,df_EC_filter,fstr)\n",
    "\n",
    "#an_final.iloc[500:520].plot()\n",
    "#an_run2.iloc[500:520].plot()\n",
    "\n",
    "#initialize df_ET\n",
    "df_ET_run2=calc_LE(df_ET,rs,ra)\n",
    "df_ET_run2['last3day_prec']=df_ET_run2['P(mast)'].rolling('72H').sum()\n",
    "\n",
    "# plot\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-07-30 00:00'\n",
    "\n",
    "#new filter\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0]\n",
    "sim_data = sim_data.resample('1H').mean()\n",
    "sim_data = sim_data.dropna()\n",
    "\n",
    "sim2_data = df_ET_run2.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "sim2_data = sim2_data.loc[sim2_data['last3day_prec']==0]\n",
    "sim2_data = sim2_data.resample('1H').mean()\n",
    "sim2_data = sim2_data.dropna()\n",
    "#sim2_data.rename(columns={'ET_VPD': 'ET_VPD2', 'last3day_prec': 'last3day_prec2'}, inplace=True)\n",
    "\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('1H').mean()\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "df_tmp2=sim2_data.copy()\n",
    "df_tmp2=df_tmp2.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "slope2, intercept2, r_value2, p_value2, std_err2 = stats.linregress(df_tmp2['LE'], df_tmp2['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value2**2)\n",
    "print('slope, intercept:', slope2, intercept2)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD'],marker='o') #scatter(x,y)\n",
    "p2=ax.scatter(df_tmp2['LE'],df_tmp2['ET_VPD'],marker='^') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='black',label='default')\n",
    "ax.axline((0.0,intercept2),slope=slope2,c='black',linestyle='dashed' ,label='Tair+1')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation simulated-measured LE. April-Oct 2017, (1hour mean) \\n default slope = {:.3f}, default R2 = {:.3f} \\n Tair+1 slope = {:.3f}, Tair+1 R2 = {:.3f}'.format(slope,r_value**2,slope2,r_value2**2))\n",
    "#ax.set_title('Tair+1 slope = {:.3f}, Tair+1 R2 = {:.3f}'.format(slope2,r_value2**2))\n",
    "ax.legend(loc='upper left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275583d8-926b-4dc3-a420-e269c59e3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second run Ag-s part\n",
    "\n",
    "# Prepare data for Run A-gs model\n",
    "#df_Comb_filter['Tair']\n",
    "#df_Comb_filter_1=df_Comb_filter.copy()\n",
    "#df_Comb_filter_1['Tair']=df_Comb_filter_1['Tair']+1\n",
    "#df_meteo_filter['L(o)corr']\n",
    "#df_Comb_filter['VPD']\n",
    "df_meteo_filter_1=df_meteo_filter_1\n",
    "df_meteo_filter_1['PAR']=df_meteo_filter_1['PAR']*1.1\n",
    "\n",
    "# Run A-gs model\n",
    "fstr=1.0\n",
    "an_run2,an_umol_run2,rs_run2, ra_run2  = runAgs(df_profile_filter,df_Comb_filter,df_meteo_filter_1,df_EC_filter,fstr)\n",
    "\n",
    "df_ET_run3=calc_LE(df_ET,rs,ra)\n",
    "df_ET_run3['last3day_prec']=df_ET_run3['P(mast)'].rolling('72H').sum()\n",
    "\n",
    "# plot\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-07-30 00:00'\n",
    "\n",
    "#new filter\n",
    "sim_data = df_ET_run3.loc[start:end,('ET_VPD','last3day_prec')]\n",
    "#sim_data = sim_data.loc[sim_data['last24h_prec']<=0.5]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0]\n",
    "sim_data= sim_data.resample('1H').mean()#.between_time(\"6:00\", \"9:00\")\n",
    "#sim_data= sim_data.between_time(\"6:00\", \"9:00\")\n",
    "sim_data=sim_data.dropna()\n",
    "\n",
    "#print(sim_data)\n",
    "\n",
    "measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('1H').mean()#.between_time(\"6:00\", \"9:00\")\n",
    "#measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].between_time(\"6:00\", \"9:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "   \n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=sim_data.copy()\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['LE'], df_tmp['ET_VPD'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "print('R2: ',r_value**2)\n",
    "print('slope, intercept:', slope, intercept)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.scatter(df_tmp['LE'],df_tmp['ET_VPD'],c=df_tmp.index.hour,cmap='viridis') #scatter(x,y)\n",
    "ax.axline((0.0,intercept),slope=slope,c='r',label='slope')\n",
    "ax.axline ((0.0,0.0), slope=1, c='r',linestyle='dashed',label='1:1')\n",
    "ax.set_ylim(-10,175)\n",
    "ax.set_xlim(-10,175)\n",
    "ax.set_xlabel(r'measured data LE (EC) [Wm$^{-2}$]')\n",
    "ax.set_ylabel(r'simulated data LE (A-gs) [Wm$^{-2}$]')\n",
    "fig.suptitle('Correlation of simulated to measured LE. April-Oct 2017, (3hour mean, 00:00-23:59) \\n intercept = {:.3f}, slope = {:.3f}, R2 = {:.3f}'.format(intercept,slope,r_value**2))\n",
    "ax.set_title('(Only days on which daily  sum of Precip. is 0)')\n",
    "ax.legend(loc='upper left')\n",
    "cbar=plt.colorbar(p1,ax=ax)\n",
    "cbar.ax.set_ylabel('Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce76d4-c59f-4b66-a64b-539dffd9b8b3",
   "metadata": {},
   "source": [
    "### WIP hourly averages section (hour as bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d760c-e3d3-4ac7-83f7-afd028858afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw binned An\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-08-30 00:00'\n",
    "\n",
    "sim_data=an_umol.loc[an_umol>0].loc[start:end].resample('1H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb['GPP_f'].loc[start:end].resample('1H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "#new filter\n",
    "#sim_data = df_ET_1.loc[start:end,('ET_VPD2','last24h_prec')]\n",
    "#sim_data = sim_data.loc[sim_data['last24h_prec']<=0.5]\n",
    "\n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=pd.DataFrame(sim_data)\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "#slope, intercept, r_value, p_value, std_err = stats.linregress(df_tmp['GPP_f'], df_tmp['sim_data'])  #linregres x, y . note r_value is Pearson's coefficient. R^2 is r_value**2\n",
    "#print('R2: ',r_value**2)\n",
    "#print('slope, intercept:', slope, intercept)\n",
    "\n",
    "hours_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "d={}\n",
    "d['meas_avg'] = [df_tmp.loc[df_tmp.index.hour==i,'GPP_f'].mean() for i in hours_list]\n",
    "d['meas_q1'] = [df_tmp.loc[df_tmp.index.hour==i,'GPP_f'].quantile(q=0.25) for i in hours_list]\n",
    "d['meas_q3'] = [df_tmp.loc[df_tmp.index.hour==i,'GPP_f'].quantile(q=0.75) for i in hours_list]\n",
    "d['sim_avg'] = [df_tmp.loc[df_tmp.index.hour==i,0].mean() for i in hours_list]\n",
    "d['sim_q1'] = [df_tmp.loc[df_tmp.index.hour==i,0].quantile(q=0.25) for i in hours_list]\n",
    "d['sim_q3'] = [df_tmp.loc[df_tmp.index.hour==i,0].quantile(q=0.75) for i in hours_list]\n",
    "\n",
    "df_avg=pd.DataFrame(d)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.plot(df_avg['meas_avg'],marker='o',label='measured')\n",
    "p2=ax.plot(df_avg['sim_avg'],marker='s',label='simulated')\n",
    "ax.fill_between(hours_list,df_avg['meas_q1'],df_avg['meas_q3'],alpha=0.1)\n",
    "ax.fill_between(hours_list,df_avg['sim_q1'],df_avg['sim_q3'],alpha=0.1)\n",
    "\n",
    "#ax.set_ylim(-5,40)\n",
    "#ax.set_xlim(-5,40)\n",
    "plt.xticks(hours_list) \n",
    "ax.set_xlabel('hour')\n",
    "ax.set_ylabel(r'Assimilation [$\\mu molm^{-2}s^{-1}$]')\n",
    "fig.suptitle('Simulated and measured An by hour, Apr-Oct 2017, (1hour mean)')\n",
    "ax.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81b16d-3418-49bc-9fb5-34d2f23bf906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw binned An\n",
    "start='2017-04-01 00:00'\n",
    "end='2017-08-30 00:00'\n",
    "\n",
    "sim_data = df_ET_1.loc[start:end,('ET_VPD','last24h_prec','last3day_prec')]\n",
    "sim_data = sim_data.loc[sim_data['last3day_prec']==0.0]\n",
    "print(sim_data.size)\n",
    "sim_data=sim_data.resample('1H').mean()\n",
    "sim_data=sim_data.dropna() #eliminate NaN entries created by the .loc slice\n",
    "measured_data=df_Comb.loc[start:end,'LE']#.resample('1H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "measured_data=measured_data.loc[measured_data>0]\n",
    "measured_data=measured_data.resample('1H').mean()\n",
    "measured_data=measured_data.dropna()\n",
    "\n",
    "#df_tmp = pd.DataFrame()\n",
    "df_tmp=pd.DataFrame(sim_data)\n",
    "df_tmp=df_tmp.merge(measured_data, how='inner',left_index=True, right_index=True)\n",
    "\n",
    "hours_list=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "\n",
    "d={}\n",
    "d['meas_avg'] = [df_tmp.loc[df_tmp.index.hour==i,'LE'].mean() for i in hours_list]\n",
    "d['meas_q1'] = [df_tmp.loc[df_tmp.index.hour==i,'LE'].quantile(q=0.25) for i in hours_list]\n",
    "d['meas_q3'] = [df_tmp.loc[df_tmp.index.hour==i,'LE'].quantile(q=0.75) for i in hours_list]\n",
    "d['sim_avg'] = [df_tmp.loc[df_tmp.index.hour==i,'ET_VPD'].mean() for i in hours_list]\n",
    "d['sim_q1'] = [df_tmp.loc[df_tmp.index.hour==i,'ET_VPD'].quantile(q=0.25) for i in hours_list]\n",
    "d['sim_q3'] = [df_tmp.loc[df_tmp.index.hour==i,'ET_VPD'].quantile(q=0.75) for i in hours_list]\n",
    "\n",
    "df_avg=pd.DataFrame(d)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "p1=ax.plot(df_avg['meas_avg'],marker='o',label='measured')\n",
    "p2=ax.plot(df_avg['sim_avg'],marker='s',label='simulated')\n",
    "ax.fill_between(hours_list,df_avg['meas_q1'],df_avg['meas_q3'],alpha=0.1)\n",
    "ax.fill_between(hours_list,df_avg['sim_q1'],df_avg['sim_q3'],alpha=0.1)\n",
    "\n",
    "#ax.set_ylim(-5,40)\n",
    "#ax.set_xlim(-5,40)\n",
    "plt.xticks(hours_list) \n",
    "ax.set_xlabel('hour')\n",
    "ax.set_ylabel(r'LE [$Wm^{-2}s^{-1}$]')\n",
    "fig.suptitle('Simulated and measured LE by hour, Apr-Oct 2017, (1hour mean)')\n",
    "ax.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4553586-fb7d-4c53-b433-2aab4a154641",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2017-04-14 00:00'\n",
    "end='2017-04-30 00:00'\n",
    "\n",
    "df_ra=pd.DataFrame({'ra':ra})\n",
    "df_rs=pd.DataFrame({'rs':rs})\n",
    "\n",
    "df_gs=pd.concat([df_profile['Pressure'],df_Comb['LE'],df_Comb['Tair'],df_Comb['VPD'],df_meteo['P(mast)'],df_meteo['R(net)'],df_meteo['G1']],axis=1,sort=False)\n",
    "df_gs['Tair_K']=df_gs['Tair']+273.15\n",
    "df_gs['p_kPa']=df_gs['Pressure']/10\n",
    "df_gs['p_kPa']=df_gs['p_kPa'].loc[df_gs['p_kPa']>1]\n",
    "df_gs['LE']=df_gs['LE'].loc[df_gs['LE']>-5]\n",
    "df_gs['VPD_adj']=df_gs['VPD'].loc[df_gs['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "df_gs['VPD_adj']=df_gs['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa\n",
    "\n",
    "#calculating q and cp\n",
    "\n",
    "    #constants:\n",
    "e_sat_0 = 0.6107 # e_sat_0 = 0.6107 kPa or 610.7 Pa\n",
    "a = 7.5\n",
    "b = 237.3 # oC (geen typo)\n",
    "df_gs['e_sat'] = e_sat_0 * 10**(a*df_gs['Tair'] / (b+df_gs['Tair'])) #  T_sfc_C in oC\n",
    "Rd = 287 # J/kg K\n",
    "Rv = 462 # J/kg K\n",
    "df_gs['q_sat'] = Rd/Rv * df_gs['e_sat']/df_gs['p_kPa'] #q = Rd/Rv * e/p -> q_sat = Rd/Rv * e_sat/p\n",
    "df_gs['e_act'] = df_gs['e_sat'] - df_gs['VPD_adj'] #VPD = e_sat - e_act -> e_act = e_sat - VPD\n",
    "df_gs['q_act'] = Rd/Rv * df_gs['e_act']/df_gs['p_kPa'] #q = Rd/Rv * e/p . output is in g/kg (order of magnitude 0.005-0.015)\n",
    "#now from q calculate cp\n",
    "cpd=1004.67 #J/kg/K\n",
    "df_gs['cp']=cpd*(1+0.84*df_gs['q_act']) #q in g/kg?\n",
    "\n",
    "#calculate inverse of aerodynamic resistance, aero conductance\n",
    "df_ra['ga'] = 1. / df_ra['ra']\n",
    "#and stomatal conductance\n",
    "df_rs['gs'] = 1. / df_rs['rs']\n",
    "\n",
    "#df_ET_runGs = pd.concat([df_meteo['L(o)'],df_meteo['Te-L(o)'],df_profile['Pressure'],df_Comb['VPD'],df_Comb['rH'],df_meteo['P(mast)']],axis=1,sort=False)\n",
    "#df_ET_runGs['p_kPa']=df_ET_runGs['Pressure']/10 # from hpa to kpa\n",
    "#df_ET_runGs['VPD_adj']=df_ET_runGs['VPD'].loc[df_ET_runGs['VPD']>0] #some outlier values for VPD are negative, remove from dataset\n",
    "#df_ET_runGs['VPD_adj']=df_ET_runGs['VPD_adj']/10  # VPD from df_Comb is in hPa, I need kPa, so hPa/10 = kPa\n",
    "\n",
    "#df_ET_runGs=calc_LE(df_ET_runGs,rs_runGs,ra_runGs)\n",
    "#df_ET_runGs['last3day_prec']=df_ET_runGs['P(mast)'].rolling('72H').sum()\n",
    "\n",
    "#sim_data = df_ET_1.loc[start:end,('ET_VPD','last24h_prec', 'T_sfc_C')]\n",
    "#measured_data=df_Comb['LE'].loc[df_Comb['LE']>0].loc[start:end].resample('3H').mean()#.between_time(\"11:00\", \"18:00\")\n",
    "\n",
    "#rs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98acd0e-98d8-41d0-a21d-66f63c4d110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs sim vs gs calculated plot\n",
    "#like in research paper by eline floor houwen\n",
    "\n",
    "df_gs=df_gs.resample('3H').mean()\n",
    "df_gs=df_gs.between_time('9:00','15:00')\n",
    "\n",
    "rho=1.2\n",
    "#cpd=1004.67 #J/kg/K\n",
    "#cp=cpd*(1+0.84q) #q in g/kg?\n",
    "cp=1006  #J/kg/K , approximation\n",
    "Lv=2.26 #MJ/kg, based on 2260000 J/kg \n",
    "\n",
    "df_gs['gamma'] = (cp * df_gs['p_kPa']) / (0.622 * Lv) #cp in J/kg/K , P in Pa, Lv in MJ/kg\n",
    "\n",
    "\n",
    "df_gs['delta'] = 4098 * (0.6108 * np.exp((17.27*df_gs['Tair'])/(df_gs['Tair']+237.3))) / ((df_gs['Tair']+237.3)**2)  # T in C, \n",
    "\n",
    "LE=df_gs['LE']\n",
    "gamma=df_gs['gamma']\n",
    "ga=df_ra['ga']\n",
    "delta=df_gs['delta']\n",
    "Rnet=df_gs['R(net)']\n",
    "G=df_gs['G1']\n",
    "cp=df_gs['cp']\n",
    "VPD=df_gs['VPD_adj']\n",
    "\n",
    "first_term = LE*gamma*ga\n",
    "second_term=delta*(Rnet-G)\n",
    "third_term=rho*cp*ga*VPD\n",
    "fourth_term=LE*(delta+gamma)\n",
    "                \n",
    "df_gs['gs'] = (first_term) / ( (second_term) + (third_term) - (fourth_term) )\n",
    "\n",
    "\n",
    "#df_gs['gs'] = (LE*gamma*ga) / ( (delta*(Rnet-G)) + (rho*cp*ga*VPD) - (LE*(delta+gamma)) )\n",
    "\n",
    "\n",
    "#df_gs['gs'] = (df_gs['LE'] * df_gs['gamma'] * df_ra['ga']) /(df_gs['delta']*(df_gs['R(net)']-df_gs['G1']) + rho*df_gs['cp']*df_ra['ga']*df_gs['VPD_adj'] - df_gs['LE']*(df_gs['delta']+df_gs['gamma']))\n",
    "\n",
    "df_gs['gs'].plot()\n",
    "#first_term.plot()\n",
    "#second_term.plot()\n",
    "#third_term.plot()\n",
    "#fourth_term.plot()\n",
    "#((second_term) + (third_term)).plot()\n",
    "#plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db0103-cd26-4156-9c51-000e07288510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs['gs'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b4f91-bc4d-43bb-bc87-95f2971cd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd=1004.67 #J/kg/K\n",
    "q=0.005\n",
    "cp=cpd*(1+0.84*q) #q in g/kg?\n",
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20441aea-4c13-49d6-961e-9f41e05695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5487fd7-30d6-4484-80ae-939131ca1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteo['R(net)'].plot()\n",
    "#df_meteo['G1'].plot()\n",
    "#(df_meteo['R(net)']-df_meteo['G1']).plot()\n",
    "\n",
    "#df_meteo['-q'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2b63-729d-4e6b-8594-b0d0e5ea1321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93575c1b-b49d-4149-8300-974ca8af37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil['SM-Lit'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-003'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-020'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-050'].loc['2017-01-01':'2017-12-30'].plot()\n",
    "df_soil['SM-100'].loc['2017-01-01':'2017-12-30'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a4030-ab17-4aeb-b65a-5a06f8279fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil['SM-Lit'].loc['2017-04-17':'2017-04-22'].plot()\n",
    "df_soil['SM-003'].loc['2017-04-17':'2017-04-22'].plot()\n",
    "df_soil['SM-020'].loc['2017-04-17':'2017-04-22'].plot()\n",
    "df_soil['SM-050'].loc['2017-04-17':'2017-04-22'].plot()\n",
    "df_soil['SM-100'].loc['2017-04-17':'2017-04-22'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdccdbc-263c-44d3-b144-96bf8384e98f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 471.85,
   "position": {
    "height": "493.844px",
    "left": "1539.19px",
    "right": "20px",
    "top": "105px",
    "width": "344px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
